{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import FrameStackObservation\n",
    "import numpy as np\n",
    "import ale_py\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import AtariPreprocessing\n",
    "import numpy as np\n",
    "import ale_py\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewards and penalties\n",
    "class LifePenaltyWrapper(gym.RewardWrapper):\n",
    "    def __init__(self, env, death_penalty=-10, move_penalty= 0, moving_target_reward = -5, influence_reward=0, point_reward = 1):\n",
    "        super(LifePenaltyWrapper, self).__init__(env)\n",
    "        self.prev_lives = 0\n",
    "        self.death_penalty = death_penalty\n",
    "        self.move_penalty = move_penalty\n",
    "        self.influence_reward = influence_reward\n",
    "        self.moving_target_reward = moving_target_reward\n",
    "        self.point_reward = point_reward\n",
    "        self.last_action = None  # Track the last action taken by the agent\n",
    "\n",
    "    def reset(self, **kwargs):\n",
    "        obs = self.env.reset(**kwargs)\n",
    "        self.prev_lives = self.env.unwrapped.ale.lives()  # Ensure lives are synced\n",
    "        self.last_action = None  # Reset last action\n",
    "        return obs\n",
    "\n",
    "    def step(self, action):\n",
    "        self.last_action = action\n",
    "        obs, reward, terminated, truncated, info = self.env.step(action)\n",
    "\n",
    "        if reward in [10, 20, 30, 40, 50]:\n",
    "            reward = self.point_reward\n",
    "        elif reward == 60:\n",
    "            reward = self.moving_target_reward\n",
    "\n",
    "        # Check if a life is lost and apply penalty\n",
    "        current_lives = self.env.unwrapped.ale.lives()\n",
    "        if current_lives < self.prev_lives:\n",
    "            reward = self.death_penalty  #when player dies the alien gives points for blowing up\n",
    "        self.prev_lives = current_lives\n",
    "\n",
    "        \n",
    "        if action in [2, 3]:  #  Penalize moving left or right\n",
    "            reward += self.move_penalty\n",
    "            \n",
    "\n",
    "        if action == 0:  # Penalize specific idle action\n",
    "            reward += 0\n",
    "\n",
    "        \n",
    "\n",
    "        return obs, reward, terminated, truncated, info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_env(seed, stack_frames=4, mode=None):\n",
    "   \n",
    "    def _init():\n",
    "        env = gym.make(\"ALE/Galaxian-v5\", frameskip=1, render_mode=mode)  # Disable default frame skipping\n",
    "        \n",
    "        env = AtariPreprocessing(env, frame_skip=3)\n",
    "        env = LifePenaltyWrapper(env)\n",
    "        env = FrameStackObservation(env, stack_size=stack_frames)\n",
    "        \n",
    "\n",
    "        # Seed the environment\n",
    "        env.action_space.seed(seed)\n",
    "        env.observation_space.seed(seed)\n",
    "        \n",
    "        return env\n",
    "    \n",
    "    return _init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Extractor CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.torch_layers import BaseFeaturesExtractor\n",
    "\n",
    "class Custom3DCNN(BaseFeaturesExtractor):\n",
    "    def __init__(self, observation_space, features_dim=256):\n",
    "        super(Custom3DCNN, self).__init__(observation_space, features_dim)\n",
    "\n",
    "        frames, height, width = observation_space.shape\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=frames, out_channels=32, kernel_size=8, stride=4),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "        with torch.no_grad():\n",
    "            sample_input = torch.zeros(1, frames, height, width)\n",
    "            n_flatten = self.cnn(sample_input).shape[1]\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(n_flatten, features_dim),\n",
    "            nn.ReLU()\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, observations):\n",
    "        return self.fc(self.cnn(observations))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(0, 255, (4, 84, 84), uint8)\n",
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import AtariPreprocessing\n",
    "import numpy as np\n",
    "import ale_py\n",
    "\n",
    "gym.register_envs(ale_py)\n",
    "\n",
    "# Create and wrap the environment\n",
    "\n",
    "vec_env = make_vec_env(\n",
    "    lambda: make_env(seed=np.random.randint(20, 60))(), \n",
    "    n_envs=4\n",
    ")\n",
    "print(vec_env.observation_space)\n",
    "\n",
    "\n",
    "# Policy kwargs to use the custom CNN\n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=Custom3DCNN,\n",
    "    features_extractor_kwargs=dict(features_dim=256),  # Output dimension of the feature extractor\n",
    ")\n",
    "\n",
    "# Create the DQN model\n",
    "model = DQN(\n",
    "    \"CnnPolicy\",  # Use a CNN-based policy\n",
    "    vec_env,\n",
    "    policy_kwargs=policy_kwargs,\n",
    "    learning_rate=1e-4,\n",
    "    buffer_size=20000,\n",
    "    learning_starts=20000,\n",
    "    batch_size=128,\n",
    "    tau=1.0,\n",
    "    gamma=0.99,\n",
    "    train_freq=(16, 'step'),\n",
    "    target_update_interval=1000,\n",
    "    exploration_fraction=0.5,\n",
    "    exploration_final_eps=0.1,\n",
    "    verbose=1,\n",
    "    device=\"cuda\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 665      |\n",
      "|    ep_rew_mean      | 14.5     |\n",
      "|    exploration_rate | 0.965    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 400      |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 3936     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 671      |\n",
      "|    ep_rew_mean      | 8.5      |\n",
      "|    exploration_rate | 0.933    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 422      |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 7412     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 787      |\n",
      "|    ep_rew_mean      | 34.7     |\n",
      "|    exploration_rate | 0.898    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 435      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 11304    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 800      |\n",
      "|    ep_rew_mean      | 55.3     |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 14216    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 835      |\n",
      "|    ep_rew_mean      | 57.9     |\n",
      "|    exploration_rate | 0.844    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 449      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 17280    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 828      |\n",
      "|    ep_rew_mean      | 51.1     |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 437      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 21744    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0986   |\n",
      "|    n_updates        | 27       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 818      |\n",
      "|    ep_rew_mean      | 50.4     |\n",
      "|    exploration_rate | 0.788    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 428      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 23548    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0363   |\n",
      "|    n_updates        | 55       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 824      |\n",
      "|    ep_rew_mean      | 54.2     |\n",
      "|    exploration_rate | 0.755    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 412      |\n",
      "|    time_elapsed     | 66       |\n",
      "|    total_timesteps  | 27276    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00396  |\n",
      "|    n_updates        | 114      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 802      |\n",
      "|    ep_rew_mean      | 48.9     |\n",
      "|    exploration_rate | 0.72     |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 410      |\n",
      "|    time_elapsed     | 75       |\n",
      "|    total_timesteps  | 31064    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.043    |\n",
      "|    n_updates        | 173      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 794      |\n",
      "|    ep_rew_mean      | 45.2     |\n",
      "|    exploration_rate | 0.693    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 416      |\n",
      "|    time_elapsed     | 81       |\n",
      "|    total_timesteps  | 34120    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.228    |\n",
      "|    n_updates        | 221      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 832      |\n",
      "|    ep_rew_mean      | 46       |\n",
      "|    exploration_rate | 0.658    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 424      |\n",
      "|    time_elapsed     | 89       |\n",
      "|    total_timesteps  | 37980    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.309    |\n",
      "|    n_updates        | 281      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 828      |\n",
      "|    ep_rew_mean      | 44.8     |\n",
      "|    exploration_rate | 0.62     |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 431      |\n",
      "|    time_elapsed     | 97       |\n",
      "|    total_timesteps  | 42252    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0498   |\n",
      "|    n_updates        | 348      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 833      |\n",
      "|    ep_rew_mean      | 46.7     |\n",
      "|    exploration_rate | 0.589    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 434      |\n",
      "|    time_elapsed     | 105      |\n",
      "|    total_timesteps  | 45704    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 402      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 840      |\n",
      "|    ep_rew_mean      | 48.6     |\n",
      "|    exploration_rate | 0.554    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 440      |\n",
      "|    time_elapsed     | 112      |\n",
      "|    total_timesteps  | 49532    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0047   |\n",
      "|    n_updates        | 461      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 881      |\n",
      "|    ep_rew_mean      | 54.1     |\n",
      "|    exploration_rate | 0.506    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 54908    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0873   |\n",
      "|    n_updates        | 545      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 904      |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.461    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 445      |\n",
      "|    time_elapsed     | 134      |\n",
      "|    total_timesteps  | 59940    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.125    |\n",
      "|    n_updates        | 624      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 900      |\n",
      "|    ep_rew_mean      | 59.8     |\n",
      "|    exploration_rate | 0.426    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 448      |\n",
      "|    time_elapsed     | 142      |\n",
      "|    total_timesteps  | 63808    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000262 |\n",
      "|    n_updates        | 684      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 904      |\n",
      "|    ep_rew_mean      | 60.4     |\n",
      "|    exploration_rate | 0.404    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 447      |\n",
      "|    time_elapsed     | 147      |\n",
      "|    total_timesteps  | 66180    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0436   |\n",
      "|    n_updates        | 722      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 907      |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.367    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 447      |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 70316    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000407 |\n",
      "|    n_updates        | 786      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 916      |\n",
      "|    ep_rew_mean      | 58.6     |\n",
      "|    exploration_rate | 0.32     |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 447      |\n",
      "|    time_elapsed     | 168      |\n",
      "|    total_timesteps  | 75524    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 868      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 941      |\n",
      "|    ep_rew_mean      | 61.7     |\n",
      "|    exploration_rate | 0.262    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 446      |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 82028    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0354   |\n",
      "|    n_updates        | 969      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 949      |\n",
      "|    ep_rew_mean      | 63.2     |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 446      |\n",
      "|    time_elapsed     | 189      |\n",
      "|    total_timesteps  | 84452    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0433   |\n",
      "|    n_updates        | 1007     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 951      |\n",
      "|    ep_rew_mean      | 62.5     |\n",
      "|    exploration_rate | 0.187    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 444      |\n",
      "|    time_elapsed     | 203      |\n",
      "|    total_timesteps  | 90352    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0778   |\n",
      "|    n_updates        | 1099     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 955      |\n",
      "|    ep_rew_mean      | 60.5     |\n",
      "|    exploration_rate | 0.151    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 212      |\n",
      "|    total_timesteps  | 94280    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0743   |\n",
      "|    n_updates        | 1161     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 955      |\n",
      "|    ep_rew_mean      | 59.2     |\n",
      "|    exploration_rate | 0.126    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 97076    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.000509 |\n",
      "|    n_updates        | 1204     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 974      |\n",
      "|    ep_rew_mean      | 60.8     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 235      |\n",
      "|    total_timesteps  | 104208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 1316     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 62.6     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 107960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.21     |\n",
      "|    n_updates        | 1374     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | 64.2     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 112232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0788   |\n",
      "|    n_updates        | 1441     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | 63.1     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 444      |\n",
      "|    time_elapsed     | 261      |\n",
      "|    total_timesteps  | 116112   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0761   |\n",
      "|    n_updates        | 1502     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 444      |\n",
      "|    time_elapsed     | 270      |\n",
      "|    total_timesteps  | 120336   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0398   |\n",
      "|    n_updates        | 1568     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.02e+03 |\n",
      "|    ep_rew_mean      | 63       |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 445      |\n",
      "|    time_elapsed     | 277      |\n",
      "|    total_timesteps  | 123680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0755   |\n",
      "|    n_updates        | 1620     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.03e+03 |\n",
      "|    ep_rew_mean      | 66.1     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 445      |\n",
      "|    time_elapsed     | 285      |\n",
      "|    total_timesteps  | 127364   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0177   |\n",
      "|    n_updates        | 1678     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.03e+03 |\n",
      "|    ep_rew_mean      | 65.3     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 446      |\n",
      "|    time_elapsed     | 293      |\n",
      "|    total_timesteps  | 130960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.121    |\n",
      "|    n_updates        | 1734     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.03e+03 |\n",
      "|    ep_rew_mean      | 66.7     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 446      |\n",
      "|    time_elapsed     | 299      |\n",
      "|    total_timesteps  | 133824   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 1778     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.03e+03 |\n",
      "|    ep_rew_mean      | 65.6     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 447      |\n",
      "|    time_elapsed     | 304      |\n",
      "|    total_timesteps  | 136292   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.189    |\n",
      "|    n_updates        | 1817     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1.01e+03 |\n",
      "|    ep_rew_mean      | 63.8     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 447      |\n",
      "|    time_elapsed     | 309      |\n",
      "|    total_timesteps  | 138456   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0737   |\n",
      "|    n_updates        | 1851     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 996      |\n",
      "|    ep_rew_mean      | 61.9     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 448      |\n",
      "|    time_elapsed     | 313      |\n",
      "|    total_timesteps  | 140524   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.153    |\n",
      "|    n_updates        | 1883     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 1e+03    |\n",
      "|    ep_rew_mean      | 61.4     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 449      |\n",
      "|    time_elapsed     | 321      |\n",
      "|    total_timesteps  | 144284   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.135    |\n",
      "|    n_updates        | 1942     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 986      |\n",
      "|    ep_rew_mean      | 57.8     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 448      |\n",
      "|    time_elapsed     | 328      |\n",
      "|    total_timesteps  | 147396   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0883   |\n",
      "|    n_updates        | 1991     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 948      |\n",
      "|    ep_rew_mean      | 52.9     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 449      |\n",
      "|    time_elapsed     | 334      |\n",
      "|    total_timesteps  | 150064   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0189   |\n",
      "|    n_updates        | 2032     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 935      |\n",
      "|    ep_rew_mean      | 46.6     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 448      |\n",
      "|    time_elapsed     | 341      |\n",
      "|    total_timesteps  | 152896   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0193   |\n",
      "|    n_updates        | 2076     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 932      |\n",
      "|    ep_rew_mean      | 46.9     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 446      |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total_timesteps  | 155740   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.209    |\n",
      "|    n_updates        | 2121     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 916      |\n",
      "|    ep_rew_mean      | 44.5     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 445      |\n",
      "|    time_elapsed     | 353      |\n",
      "|    total_timesteps  | 157492   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0467   |\n",
      "|    n_updates        | 2148     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 907      |\n",
      "|    ep_rew_mean      | 44.7     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 361      |\n",
      "|    total_timesteps  | 160552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0804   |\n",
      "|    n_updates        | 2196     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 887      |\n",
      "|    ep_rew_mean      | 42.2     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 368      |\n",
      "|    total_timesteps  | 163240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0475   |\n",
      "|    n_updates        | 2238     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 853      |\n",
      "|    ep_rew_mean      | 38.5     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 371      |\n",
      "|    total_timesteps  | 164632   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0105   |\n",
      "|    n_updates        | 2260     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 825      |\n",
      "|    ep_rew_mean      | 34       |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 376      |\n",
      "|    total_timesteps  | 166428   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0481   |\n",
      "|    n_updates        | 2288     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 807      |\n",
      "|    ep_rew_mean      | 32.6     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 382      |\n",
      "|    total_timesteps  | 169396   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 2334     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 784      |\n",
      "|    ep_rew_mean      | 32.3     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 387      |\n",
      "|    total_timesteps  | 171640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 2369     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 773      |\n",
      "|    ep_rew_mean      | 32.4     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 391      |\n",
      "|    total_timesteps  | 173344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.149    |\n",
      "|    n_updates        | 2396     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 746      |\n",
      "|    ep_rew_mean      | 29.5     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 397      |\n",
      "|    total_timesteps  | 175836   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0163   |\n",
      "|    n_updates        | 2435     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 718      |\n",
      "|    ep_rew_mean      | 28.1     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 403      |\n",
      "|    total_timesteps  | 178788   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0167   |\n",
      "|    n_updates        | 2481     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 697      |\n",
      "|    ep_rew_mean      | 25.5     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 442      |\n",
      "|    time_elapsed     | 409      |\n",
      "|    total_timesteps  | 181412   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.113    |\n",
      "|    n_updates        | 2522     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 692      |\n",
      "|    ep_rew_mean      | 21.5     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 415      |\n",
      "|    total_timesteps  | 184296   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0878   |\n",
      "|    n_updates        | 2567     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 675      |\n",
      "|    ep_rew_mean      | 18.6     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 420      |\n",
      "|    total_timesteps  | 186356   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.165    |\n",
      "|    n_updates        | 2599     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 662      |\n",
      "|    ep_rew_mean      | 18.4     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 425      |\n",
      "|    total_timesteps  | 188936   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 2640     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 651      |\n",
      "|    ep_rew_mean      | 14.1     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 432      |\n",
      "|    total_timesteps  | 191804   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.173    |\n",
      "|    n_updates        | 2684     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 643      |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 439      |\n",
      "|    total_timesteps  | 194880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 2732     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 637      |\n",
      "|    ep_rew_mean      | 12.4     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 444      |\n",
      "|    total_timesteps  | 197036   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.17     |\n",
      "|    n_updates        | 2766     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 638      |\n",
      "|    ep_rew_mean      | 12.9     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 443      |\n",
      "|    time_elapsed     | 448      |\n",
      "|    total_timesteps  | 198968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0957   |\n",
      "|    n_updates        | 2796     |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=10000,   # Save every 10,000 steps\n",
    "    save_path='./checkpoints/',  # Directory to save the model\n",
    "    name_prefix='new_V1_train'  # Prefix for the checkpoint filenames\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.learn(total_timesteps=200000, callback=checkpoint_callback)\n",
    "\n",
    "# Save the model\n",
    "model.save(\"new_v1_dqn_galaxian\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devpa\\anaconda3\\envs\\atari\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:241: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 1.13GB > 1.03GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 437      |\n",
      "|    ep_rew_mean      | -48.8    |\n",
      "|    exploration_rate | 0.297    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 856      |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 4592     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 603      |\n",
      "|    ep_rew_mean      | -29.8    |\n",
      "|    exploration_rate | 0.295    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 956      |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 7504     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 744      |\n",
      "|    ep_rew_mean      | -19.6    |\n",
      "|    exploration_rate | 0.292    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 1031     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 12368    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 722      |\n",
      "|    ep_rew_mean      | -26.6    |\n",
      "|    exploration_rate | 0.291    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 1042     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 13984    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 738      |\n",
      "|    ep_rew_mean      | -32.2    |\n",
      "|    exploration_rate | 0.289    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 1037     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 16552    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 713      |\n",
      "|    ep_rew_mean      | -31      |\n",
      "|    exploration_rate | 0.287    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 1040     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 19288    |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 702      |\n",
      "|    ep_rew_mean      | -28.1    |\n",
      "|    exploration_rate | 0.285    |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 918      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 23136    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0534   |\n",
      "|    n_updates        | 105074   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 717      |\n",
      "|    ep_rew_mean      | -21.8    |\n",
      "|    exploration_rate | 0.283    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 890      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 24776    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.138    |\n",
      "|    n_updates        | 105076   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 705      |\n",
      "|    ep_rew_mean      | -21.7    |\n",
      "|    exploration_rate | 0.281    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 855      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 28784    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.091    |\n",
      "|    n_updates        | 105080   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 686      |\n",
      "|    ep_rew_mean      | -22.4    |\n",
      "|    exploration_rate | 0.279    |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 819      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 31664    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 105082   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 717      |\n",
      "|    ep_rew_mean      | -19.5    |\n",
      "|    exploration_rate | 0.276    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 757      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 36496    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0315   |\n",
      "|    n_updates        | 105087   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 715      |\n",
      "|    ep_rew_mean      | -16.8    |\n",
      "|    exploration_rate | 0.275    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 756      |\n",
      "|    time_elapsed     | 50       |\n",
      "|    total_timesteps  | 37952    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.658    |\n",
      "|    n_updates        | 105089   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 744      |\n",
      "|    ep_rew_mean      | -5.02    |\n",
      "|    exploration_rate | 0.272    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 745      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 41256    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.065    |\n",
      "|    n_updates        | 105092   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 738      |\n",
      "|    ep_rew_mean      | -4.38    |\n",
      "|    exploration_rate | 0.271    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 741      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 42864    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 105093   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 747      |\n",
      "|    ep_rew_mean      | -5.42    |\n",
      "|    exploration_rate | 0.268    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 730      |\n",
      "|    time_elapsed     | 65       |\n",
      "|    total_timesteps  | 47952    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.717    |\n",
      "|    n_updates        | 105098   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 746      |\n",
      "|    ep_rew_mean      | -6.11    |\n",
      "|    exploration_rate | 0.267    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 728      |\n",
      "|    time_elapsed     | 68       |\n",
      "|    total_timesteps  | 49904    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0894   |\n",
      "|    n_updates        | 105100   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 744      |\n",
      "|    ep_rew_mean      | -8.12    |\n",
      "|    exploration_rate | 0.264    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 718      |\n",
      "|    time_elapsed     | 74       |\n",
      "|    total_timesteps  | 53304    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0439   |\n",
      "|    n_updates        | 105104   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 744      |\n",
      "|    ep_rew_mean      | -7.43    |\n",
      "|    exploration_rate | 0.263    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 705      |\n",
      "|    time_elapsed     | 79       |\n",
      "|    total_timesteps  | 55728    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 105106   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 735      |\n",
      "|    ep_rew_mean      | -9.57    |\n",
      "|    exploration_rate | 0.26     |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 690      |\n",
      "|    time_elapsed     | 86       |\n",
      "|    total_timesteps  | 59456    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.732    |\n",
      "|    n_updates        | 105110   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 744      |\n",
      "|    ep_rew_mean      | -6.51    |\n",
      "|    exploration_rate | 0.258    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 681      |\n",
      "|    time_elapsed     | 91       |\n",
      "|    total_timesteps  | 62536    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 105113   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 742      |\n",
      "|    ep_rew_mean      | -6.6     |\n",
      "|    exploration_rate | 0.257    |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 674      |\n",
      "|    time_elapsed     | 95       |\n",
      "|    total_timesteps  | 64424    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.249    |\n",
      "|    n_updates        | 105114   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 734      |\n",
      "|    ep_rew_mean      | -7.5     |\n",
      "|    exploration_rate | 0.255    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 669      |\n",
      "|    time_elapsed     | 100      |\n",
      "|    total_timesteps  | 67224    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0776   |\n",
      "|    n_updates        | 105117   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 727      |\n",
      "|    ep_rew_mean      | -8.74    |\n",
      "|    exploration_rate | 0.253    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 664      |\n",
      "|    time_elapsed     | 106      |\n",
      "|    total_timesteps  | 70808    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0463   |\n",
      "|    n_updates        | 105121   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 735      |\n",
      "|    ep_rew_mean      | -9.03    |\n",
      "|    exploration_rate | 0.251    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 658      |\n",
      "|    time_elapsed     | 111      |\n",
      "|    total_timesteps  | 73320    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.267    |\n",
      "|    n_updates        | 105123   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 733      |\n",
      "|    ep_rew_mean      | -9.16    |\n",
      "|    exploration_rate | 0.249    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 654      |\n",
      "|    time_elapsed     | 115      |\n",
      "|    total_timesteps  | 75896    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.112    |\n",
      "|    n_updates        | 105126   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 739      |\n",
      "|    ep_rew_mean      | -6.93    |\n",
      "|    exploration_rate | 0.247    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 651      |\n",
      "|    time_elapsed     | 121      |\n",
      "|    total_timesteps  | 79096    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0351   |\n",
      "|    n_updates        | 105129   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 731      |\n",
      "|    ep_rew_mean      | -6.84    |\n",
      "|    exploration_rate | 0.246    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 651      |\n",
      "|    time_elapsed     | 123      |\n",
      "|    total_timesteps  | 80272    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 105130   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 715      |\n",
      "|    ep_rew_mean      | -8.13    |\n",
      "|    exploration_rate | 0.245    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 649      |\n",
      "|    time_elapsed     | 127      |\n",
      "|    total_timesteps  | 82592    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.166    |\n",
      "|    n_updates        | 105132   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 714      |\n",
      "|    ep_rew_mean      | -6.62    |\n",
      "|    exploration_rate | 0.242    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 647      |\n",
      "|    time_elapsed     | 133      |\n",
      "|    total_timesteps  | 86632    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0988   |\n",
      "|    n_updates        | 105136   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 707      |\n",
      "|    ep_rew_mean      | -5.7     |\n",
      "|    exploration_rate | 0.241    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 644      |\n",
      "|    time_elapsed     | 137      |\n",
      "|    total_timesteps  | 88864    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.121    |\n",
      "|    n_updates        | 105138   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 716      |\n",
      "|    ep_rew_mean      | -5.28    |\n",
      "|    exploration_rate | 0.24     |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 642      |\n",
      "|    time_elapsed     | 140      |\n",
      "|    total_timesteps  | 90504    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 105140   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 714      |\n",
      "|    ep_rew_mean      | -7.18    |\n",
      "|    exploration_rate | 0.238    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 639      |\n",
      "|    time_elapsed     | 145      |\n",
      "|    total_timesteps  | 93368    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0593   |\n",
      "|    n_updates        | 105143   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 704      |\n",
      "|    ep_rew_mean      | -9.17    |\n",
      "|    exploration_rate | 0.236    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 641      |\n",
      "|    time_elapsed     | 150      |\n",
      "|    total_timesteps  | 96192    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.207    |\n",
      "|    n_updates        | 105145   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 707      |\n",
      "|    ep_rew_mean      | -9.95    |\n",
      "|    exploration_rate | 0.234    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 640      |\n",
      "|    time_elapsed     | 154      |\n",
      "|    total_timesteps  | 99152    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.139    |\n",
      "|    n_updates        | 105148   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 713      |\n",
      "|    ep_rew_mean      | -10.5    |\n",
      "|    exploration_rate | 0.233    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 638      |\n",
      "|    time_elapsed     | 157      |\n",
      "|    total_timesteps  | 100632   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.139    |\n",
      "|    n_updates        | 105150   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 698      |\n",
      "|    ep_rew_mean      | -11.3    |\n",
      "|    exploration_rate | 0.23     |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 636      |\n",
      "|    time_elapsed     | 163      |\n",
      "|    total_timesteps  | 104256   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.184    |\n",
      "|    n_updates        | 105153   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 696      |\n",
      "|    ep_rew_mean      | -11.7    |\n",
      "|    exploration_rate | 0.228    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 634      |\n",
      "|    time_elapsed     | 169      |\n",
      "|    total_timesteps  | 107544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.196    |\n",
      "|    n_updates        | 105157   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 685      |\n",
      "|    ep_rew_mean      | -15.2    |\n",
      "|    exploration_rate | 0.227    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 633      |\n",
      "|    time_elapsed     | 173      |\n",
      "|    total_timesteps  | 110024   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0378   |\n",
      "|    n_updates        | 105159   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 688      |\n",
      "|    ep_rew_mean      | -16.2    |\n",
      "|    exploration_rate | 0.225    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 633      |\n",
      "|    time_elapsed     | 177      |\n",
      "|    total_timesteps  | 112712   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.188    |\n",
      "|    n_updates        | 105162   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 684      |\n",
      "|    ep_rew_mean      | -16.3    |\n",
      "|    exploration_rate | 0.222    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 634      |\n",
      "|    time_elapsed     | 183      |\n",
      "|    total_timesteps  | 116440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.811    |\n",
      "|    n_updates        | 105165   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 680      |\n",
      "|    ep_rew_mean      | -15.3    |\n",
      "|    exploration_rate | 0.221    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 635      |\n",
      "|    time_elapsed     | 185      |\n",
      "|    total_timesteps  | 118048   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.165    |\n",
      "|    n_updates        | 105167   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 674      |\n",
      "|    ep_rew_mean      | -16      |\n",
      "|    exploration_rate | 0.219    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 633      |\n",
      "|    time_elapsed     | 192      |\n",
      "|    total_timesteps  | 122144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 105171   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 678      |\n",
      "|    ep_rew_mean      | -16.9    |\n",
      "|    exploration_rate | 0.217    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 630      |\n",
      "|    time_elapsed     | 198      |\n",
      "|    total_timesteps  | 125136   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 105174   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 677      |\n",
      "|    ep_rew_mean      | -15.3    |\n",
      "|    exploration_rate | 0.215    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 629      |\n",
      "|    time_elapsed     | 202      |\n",
      "|    total_timesteps  | 127736   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.114    |\n",
      "|    n_updates        | 105176   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 685      |\n",
      "|    ep_rew_mean      | -12.6    |\n",
      "|    exploration_rate | 0.213    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 627      |\n",
      "|    time_elapsed     | 207      |\n",
      "|    total_timesteps  | 130200   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0999   |\n",
      "|    n_updates        | 105179   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 680      |\n",
      "|    ep_rew_mean      | -13      |\n",
      "|    exploration_rate | 0.211    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 620      |\n",
      "|    time_elapsed     | 216      |\n",
      "|    total_timesteps  | 134224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0539   |\n",
      "|    n_updates        | 105183   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 692      |\n",
      "|    ep_rew_mean      | -11.8    |\n",
      "|    exploration_rate | 0.21     |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 618      |\n",
      "|    time_elapsed     | 219      |\n",
      "|    total_timesteps  | 135576   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.179    |\n",
      "|    n_updates        | 105184   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 689      |\n",
      "|    ep_rew_mean      | -11.7    |\n",
      "|    exploration_rate | 0.207    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 615      |\n",
      "|    time_elapsed     | 226      |\n",
      "|    total_timesteps  | 139144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.191    |\n",
      "|    n_updates        | 105187   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 676      |\n",
      "|    ep_rew_mean      | -12.5    |\n",
      "|    exploration_rate | 0.206    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 612      |\n",
      "|    time_elapsed     | 231      |\n",
      "|    total_timesteps  | 141472   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.185    |\n",
      "|    n_updates        | 105190   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 667      |\n",
      "|    ep_rew_mean      | -13.4    |\n",
      "|    exploration_rate | 0.205    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 611      |\n",
      "|    time_elapsed     | 233      |\n",
      "|    total_timesteps  | 142800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 105191   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 679      |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.203    |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 612      |\n",
      "|    time_elapsed     | 238      |\n",
      "|    total_timesteps  | 145704   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 105194   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 676      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.201    |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 610      |\n",
      "|    time_elapsed     | 243      |\n",
      "|    total_timesteps  | 148824   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.082    |\n",
      "|    n_updates        | 105197   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 675      |\n",
      "|    ep_rew_mean      | -12.6    |\n",
      "|    exploration_rate | 0.198    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 605      |\n",
      "|    time_elapsed     | 252      |\n",
      "|    total_timesteps  | 152952   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.749    |\n",
      "|    n_updates        | 105201   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 688      |\n",
      "|    ep_rew_mean      | -12.9    |\n",
      "|    exploration_rate | 0.196    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 603      |\n",
      "|    time_elapsed     | 258      |\n",
      "|    total_timesteps  | 156216   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 105204   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 709      |\n",
      "|    ep_rew_mean      | -8.64    |\n",
      "|    exploration_rate | 0.194    |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 597      |\n",
      "|    time_elapsed     | 266      |\n",
      "|    total_timesteps  | 159256   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0299   |\n",
      "|    n_updates        | 105207   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 703      |\n",
      "|    ep_rew_mean      | -9.36    |\n",
      "|    exploration_rate | 0.192    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 594      |\n",
      "|    time_elapsed     | 273      |\n",
      "|    total_timesteps  | 162296   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0873   |\n",
      "|    n_updates        | 105210   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 704      |\n",
      "|    ep_rew_mean      | -7.67    |\n",
      "|    exploration_rate | 0.19     |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 593      |\n",
      "|    time_elapsed     | 278      |\n",
      "|    total_timesteps  | 165120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.139    |\n",
      "|    n_updates        | 105213   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 704      |\n",
      "|    ep_rew_mean      | -7.9     |\n",
      "|    exploration_rate | 0.188    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 593      |\n",
      "|    time_elapsed     | 282      |\n",
      "|    total_timesteps  | 167736   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 105215   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 716      |\n",
      "|    ep_rew_mean      | -7.44    |\n",
      "|    exploration_rate | 0.185    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 593      |\n",
      "|    time_elapsed     | 289      |\n",
      "|    total_timesteps  | 172160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0699   |\n",
      "|    n_updates        | 105220   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 715      |\n",
      "|    ep_rew_mean      | -7.27    |\n",
      "|    exploration_rate | 0.184    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 592      |\n",
      "|    time_elapsed     | 294      |\n",
      "|    total_timesteps  | 174248   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.074    |\n",
      "|    n_updates        | 105222   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 716      |\n",
      "|    ep_rew_mean      | -9.09    |\n",
      "|    exploration_rate | 0.183    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 590      |\n",
      "|    time_elapsed     | 298      |\n",
      "|    total_timesteps  | 176008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0598   |\n",
      "|    n_updates        | 105223   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 709      |\n",
      "|    ep_rew_mean      | -10.7    |\n",
      "|    exploration_rate | 0.181    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 590      |\n",
      "|    time_elapsed     | 301      |\n",
      "|    total_timesteps  | 178088   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0653   |\n",
      "|    n_updates        | 105225   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 693      |\n",
      "|    ep_rew_mean      | -12.8    |\n",
      "|    exploration_rate | 0.179    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 308      |\n",
      "|    total_timesteps  | 181376   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.133    |\n",
      "|    n_updates        | 105229   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 686      |\n",
      "|    ep_rew_mean      | -13.3    |\n",
      "|    exploration_rate | 0.177    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 315      |\n",
      "|    total_timesteps  | 185016   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0839   |\n",
      "|    n_updates        | 105232   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 707      |\n",
      "|    ep_rew_mean      | -12.1    |\n",
      "|    exploration_rate | 0.175    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 320      |\n",
      "|    total_timesteps  | 187576   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0862   |\n",
      "|    n_updates        | 105235   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 724      |\n",
      "|    ep_rew_mean      | -12.7    |\n",
      "|    exploration_rate | 0.173    |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 325      |\n",
      "|    total_timesteps  | 190904   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.172    |\n",
      "|    n_updates        | 105238   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 725      |\n",
      "|    ep_rew_mean      | -11.4    |\n",
      "|    exploration_rate | 0.171    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 329      |\n",
      "|    total_timesteps  | 192928   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0393   |\n",
      "|    n_updates        | 105240   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 723      |\n",
      "|    ep_rew_mean      | -11.9    |\n",
      "|    exploration_rate | 0.169    |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 335      |\n",
      "|    total_timesteps  | 196784   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0584   |\n",
      "|    n_updates        | 105244   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 730      |\n",
      "|    ep_rew_mean      | -11.9    |\n",
      "|    exploration_rate | 0.168    |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 338      |\n",
      "|    total_timesteps  | 198696   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0349   |\n",
      "|    n_updates        | 105246   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 711      |\n",
      "|    ep_rew_mean      | -17      |\n",
      "|    exploration_rate | 0.166    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 343      |\n",
      "|    total_timesteps  | 201360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.031    |\n",
      "|    n_updates        | 105248   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 717      |\n",
      "|    ep_rew_mean      | -17.2    |\n",
      "|    exploration_rate | 0.163    |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 349      |\n",
      "|    total_timesteps  | 204872   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.067    |\n",
      "|    n_updates        | 105252   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 707      |\n",
      "|    ep_rew_mean      | -18.5    |\n",
      "|    exploration_rate | 0.161    |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 356      |\n",
      "|    total_timesteps  | 209056   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.107    |\n",
      "|    n_updates        | 105256   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 719      |\n",
      "|    ep_rew_mean      | -14.8    |\n",
      "|    exploration_rate | 0.159    |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 360      |\n",
      "|    total_timesteps  | 211432   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0267   |\n",
      "|    n_updates        | 105258   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 727      |\n",
      "|    ep_rew_mean      | -14.2    |\n",
      "|    exploration_rate | 0.157    |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 366      |\n",
      "|    total_timesteps  | 214696   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0918   |\n",
      "|    n_updates        | 105261   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 749      |\n",
      "|    ep_rew_mean      | -9.72    |\n",
      "|    exploration_rate | 0.155    |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 370      |\n",
      "|    total_timesteps  | 217552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0764   |\n",
      "|    n_updates        | 105264   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 743      |\n",
      "|    ep_rew_mean      | -10.9    |\n",
      "|    exploration_rate | 0.153    |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 374      |\n",
      "|    total_timesteps  | 220304   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0929   |\n",
      "|    n_updates        | 105267   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 744      |\n",
      "|    ep_rew_mean      | -9.7     |\n",
      "|    exploration_rate | 0.152    |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 378      |\n",
      "|    total_timesteps  | 222680   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.081    |\n",
      "|    n_updates        | 105269   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 746      |\n",
      "|    ep_rew_mean      | -9.51    |\n",
      "|    exploration_rate | 0.15     |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 383      |\n",
      "|    total_timesteps  | 225536   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0486   |\n",
      "|    n_updates        | 105272   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 732      |\n",
      "|    ep_rew_mean      | -9.93    |\n",
      "|    exploration_rate | 0.148    |\n",
      "| time/               |          |\n",
      "|    episodes         | 316      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 386      |\n",
      "|    total_timesteps  | 227392   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0261   |\n",
      "|    n_updates        | 105274   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 711      |\n",
      "|    ep_rew_mean      | -12.7    |\n",
      "|    exploration_rate | 0.145    |\n",
      "| time/               |          |\n",
      "|    episodes         | 320      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 394      |\n",
      "|    total_timesteps  | 232432   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0555   |\n",
      "|    n_updates        | 105278   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 731      |\n",
      "|    ep_rew_mean      | -12.2    |\n",
      "|    exploration_rate | 0.143    |\n",
      "| time/               |          |\n",
      "|    episodes         | 324      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 399      |\n",
      "|    total_timesteps  | 234864   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0663   |\n",
      "|    n_updates        | 105281   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 734      |\n",
      "|    ep_rew_mean      | -11.5    |\n",
      "|    exploration_rate | 0.142    |\n",
      "| time/               |          |\n",
      "|    episodes         | 328      |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 404      |\n",
      "|    total_timesteps  | 237496   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.735    |\n",
      "|    n_updates        | 105283   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 731      |\n",
      "|    ep_rew_mean      | -12.3    |\n",
      "|    exploration_rate | 0.14     |\n",
      "| time/               |          |\n",
      "|    episodes         | 332      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 410      |\n",
      "|    total_timesteps  | 240632   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0678   |\n",
      "|    n_updates        | 105286   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 723      |\n",
      "|    ep_rew_mean      | -12.4    |\n",
      "|    exploration_rate | 0.138    |\n",
      "| time/               |          |\n",
      "|    episodes         | 336      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 415      |\n",
      "|    total_timesteps  | 243360   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0651   |\n",
      "|    n_updates        | 105289   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 736      |\n",
      "|    ep_rew_mean      | -8.95    |\n",
      "|    exploration_rate | 0.134    |\n",
      "| time/               |          |\n",
      "|    episodes         | 340      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 425      |\n",
      "|    total_timesteps  | 249640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0379   |\n",
      "|    n_updates        | 105295   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 748      |\n",
      "|    ep_rew_mean      | -7.96    |\n",
      "|    exploration_rate | 0.132    |\n",
      "| time/               |          |\n",
      "|    episodes         | 344      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 428      |\n",
      "|    total_timesteps  | 251272   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.064    |\n",
      "|    n_updates        | 105297   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 767      |\n",
      "|    ep_rew_mean      | -6.16    |\n",
      "|    exploration_rate | 0.13     |\n",
      "| time/               |          |\n",
      "|    episodes         | 348      |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 433      |\n",
      "|    total_timesteps  | 254824   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0461   |\n",
      "|    n_updates        | 105300   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 782      |\n",
      "|    ep_rew_mean      | -4.66    |\n",
      "|    exploration_rate | 0.128    |\n",
      "| time/               |          |\n",
      "|    episodes         | 352      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 437      |\n",
      "|    total_timesteps  | 257752   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00233  |\n",
      "|    n_updates        | 105303   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 785      |\n",
      "|    ep_rew_mean      | -4.01    |\n",
      "|    exploration_rate | 0.128    |\n",
      "| time/               |          |\n",
      "|    episodes         | 356      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 438      |\n",
      "|    total_timesteps  | 258432   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.13     |\n",
      "|    n_updates        | 105304   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 759      |\n",
      "|    ep_rew_mean      | -6.47    |\n",
      "|    exploration_rate | 0.125    |\n",
      "| time/               |          |\n",
      "|    episodes         | 360      |\n",
      "|    fps              | 590      |\n",
      "|    time_elapsed     | 444      |\n",
      "|    total_timesteps  | 262248   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.04     |\n",
      "|    n_updates        | 105308   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 746      |\n",
      "|    ep_rew_mean      | -6.28    |\n",
      "|    exploration_rate | 0.124    |\n",
      "| time/               |          |\n",
      "|    episodes         | 364      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 448      |\n",
      "|    total_timesteps  | 264464   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0471   |\n",
      "|    n_updates        | 105310   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 749      |\n",
      "|    ep_rew_mean      | -5.72    |\n",
      "|    exploration_rate | 0.122    |\n",
      "| time/               |          |\n",
      "|    episodes         | 368      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 453      |\n",
      "|    total_timesteps  | 267552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.172    |\n",
      "|    n_updates        | 105313   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 736      |\n",
      "|    ep_rew_mean      | -6.56    |\n",
      "|    exploration_rate | 0.121    |\n",
      "| time/               |          |\n",
      "|    episodes         | 372      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 456      |\n",
      "|    total_timesteps  | 269240   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 105314   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 728      |\n",
      "|    ep_rew_mean      | -6.45    |\n",
      "|    exploration_rate | 0.118    |\n",
      "| time/               |          |\n",
      "|    episodes         | 376      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 461      |\n",
      "|    total_timesteps  | 272336   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.224    |\n",
      "|    n_updates        | 105317   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 737      |\n",
      "|    ep_rew_mean      | -8.3     |\n",
      "|    exploration_rate | 0.116    |\n",
      "| time/               |          |\n",
      "|    episodes         | 380      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 468      |\n",
      "|    total_timesteps  | 276104   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0188   |\n",
      "|    n_updates        | 105321   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 732      |\n",
      "|    ep_rew_mean      | -7.4     |\n",
      "|    exploration_rate | 0.113    |\n",
      "| time/               |          |\n",
      "|    episodes         | 384      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 474      |\n",
      "|    total_timesteps  | 279832   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00976  |\n",
      "|    n_updates        | 105325   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 744      |\n",
      "|    ep_rew_mean      | -7.85    |\n",
      "|    exploration_rate | 0.113    |\n",
      "| time/               |          |\n",
      "|    episodes         | 388      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 477      |\n",
      "|    total_timesteps  | 280960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.649    |\n",
      "|    n_updates        | 105326   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 739      |\n",
      "|    ep_rew_mean      | -9.99    |\n",
      "|    exploration_rate | 0.11     |\n",
      "| time/               |          |\n",
      "|    episodes         | 392      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 485      |\n",
      "|    total_timesteps  | 285528   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 105330   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 753      |\n",
      "|    ep_rew_mean      | -7.05    |\n",
      "|    exploration_rate | 0.106    |\n",
      "| time/               |          |\n",
      "|    episodes         | 396      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 493      |\n",
      "|    total_timesteps  | 291056   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.154    |\n",
      "|    n_updates        | 105336   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 746      |\n",
      "|    ep_rew_mean      | -8.4     |\n",
      "|    exploration_rate | 0.105    |\n",
      "| time/               |          |\n",
      "|    episodes         | 400      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 497      |\n",
      "|    total_timesteps  | 292864   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.095    |\n",
      "|    n_updates        | 105337   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 750      |\n",
      "|    ep_rew_mean      | -7.04    |\n",
      "|    exploration_rate | 0.103    |\n",
      "| time/               |          |\n",
      "|    episodes         | 404      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 502      |\n",
      "|    total_timesteps  | 295952   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.124    |\n",
      "|    n_updates        | 105341   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 754      |\n",
      "|    ep_rew_mean      | -8.25    |\n",
      "|    exploration_rate | 0.101    |\n",
      "| time/               |          |\n",
      "|    episodes         | 408      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 505      |\n",
      "|    total_timesteps  | 297840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0537   |\n",
      "|    n_updates        | 105342   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 756      |\n",
      "|    ep_rew_mean      | -8.77    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 412      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 511      |\n",
      "|    total_timesteps  | 301328   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0143   |\n",
      "|    n_updates        | 105346   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 760      |\n",
      "|    ep_rew_mean      | -9.68    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 416      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 513      |\n",
      "|    total_timesteps  | 302624   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0545   |\n",
      "|    n_updates        | 105347   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 755      |\n",
      "|    ep_rew_mean      | -10.9    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 420      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 519      |\n",
      "|    total_timesteps  | 306184   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.132    |\n",
      "|    n_updates        | 105351   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 733      |\n",
      "|    ep_rew_mean      | -11.5    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 424      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 522      |\n",
      "|    total_timesteps  | 307592   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.13     |\n",
      "|    n_updates        | 105352   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 731      |\n",
      "|    ep_rew_mean      | -11.1    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 428      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 528      |\n",
      "|    total_timesteps  | 310984   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0397   |\n",
      "|    n_updates        | 105355   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 743      |\n",
      "|    ep_rew_mean      | -8.91    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 432      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 533      |\n",
      "|    total_timesteps  | 313624   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0762   |\n",
      "|    n_updates        | 105358   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 737      |\n",
      "|    ep_rew_mean      | -8.92    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 436      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 536      |\n",
      "|    total_timesteps  | 316152   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.162    |\n",
      "|    n_updates        | 105360   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 724      |\n",
      "|    ep_rew_mean      | -11.9    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 440      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 543      |\n",
      "|    total_timesteps  | 320280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0329   |\n",
      "|    n_updates        | 105364   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 714      |\n",
      "|    ep_rew_mean      | -11.1    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 444      |\n",
      "|    fps              | 590      |\n",
      "|    time_elapsed     | 547      |\n",
      "|    total_timesteps  | 323440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.141    |\n",
      "|    n_updates        | 105367   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 716      |\n",
      "|    ep_rew_mean      | -10      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 448      |\n",
      "|    fps              | 591      |\n",
      "|    time_elapsed     | 553      |\n",
      "|    total_timesteps  | 327344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0893   |\n",
      "|    n_updates        | 105371   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 725      |\n",
      "|    ep_rew_mean      | -11.1    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 452      |\n",
      "|    fps              | 590      |\n",
      "|    time_elapsed     | 558      |\n",
      "|    total_timesteps  | 329832   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00577  |\n",
      "|    n_updates        | 105374   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 722      |\n",
      "|    ep_rew_mean      | -12.7    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 456      |\n",
      "|    fps              | 590      |\n",
      "|    time_elapsed     | 564      |\n",
      "|    total_timesteps  | 332928   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.011    |\n",
      "|    n_updates        | 105377   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 745      |\n",
      "|    ep_rew_mean      | -5.65    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 460      |\n",
      "|    fps              | 590      |\n",
      "|    time_elapsed     | 576      |\n",
      "|    total_timesteps  | 340216   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.126    |\n",
      "|    n_updates        | 105384   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 756      |\n",
      "|    ep_rew_mean      | -3.5     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 464      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 583      |\n",
      "|    total_timesteps  | 344072   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.643    |\n",
      "|    n_updates        | 105388   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 776      |\n",
      "|    ep_rew_mean      | -3.34    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 468      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 589      |\n",
      "|    total_timesteps  | 347928   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.209    |\n",
      "|    n_updates        | 105391   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 784      |\n",
      "|    ep_rew_mean      | -1.62    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 472      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 596      |\n",
      "|    total_timesteps  | 351520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0318   |\n",
      "|    n_updates        | 105395   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 818      |\n",
      "|    ep_rew_mean      | 3.14     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 476      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 599      |\n",
      "|    total_timesteps  | 353472   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 105397   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 803      |\n",
      "|    ep_rew_mean      | 4.14     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 480      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 604      |\n",
      "|    total_timesteps  | 356048   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0281   |\n",
      "|    n_updates        | 105399   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 802      |\n",
      "|    ep_rew_mean      | 2.53     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 484      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 611      |\n",
      "|    total_timesteps  | 360128   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0714   |\n",
      "|    n_updates        | 105403   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 800      |\n",
      "|    ep_rew_mean      | 3.54     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 488      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 615      |\n",
      "|    total_timesteps  | 362944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 105406   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 811      |\n",
      "|    ep_rew_mean      | 2.97     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 492      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 619      |\n",
      "|    total_timesteps  | 364920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0662   |\n",
      "|    n_updates        | 105408   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 789      |\n",
      "|    ep_rew_mean      | -0.51    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 496      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 624      |\n",
      "|    total_timesteps  | 367768   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0568   |\n",
      "|    n_updates        | 105411   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 786      |\n",
      "|    ep_rew_mean      | -2.38    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 500      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 631      |\n",
      "|    total_timesteps  | 371784   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.114    |\n",
      "|    n_updates        | 105415   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 777      |\n",
      "|    ep_rew_mean      | -5.15    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 504      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 632      |\n",
      "|    total_timesteps  | 372864   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0803   |\n",
      "|    n_updates        | 105416   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 778      |\n",
      "|    ep_rew_mean      | -4.16    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 508      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 640      |\n",
      "|    total_timesteps  | 377744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 105420   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 785      |\n",
      "|    ep_rew_mean      | -3.83    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 512      |\n",
      "|    fps              | 590      |\n",
      "|    time_elapsed     | 643      |\n",
      "|    total_timesteps  | 379760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0147   |\n",
      "|    n_updates        | 105422   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 785      |\n",
      "|    ep_rew_mean      | -2.28    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 516      |\n",
      "|    fps              | 591      |\n",
      "|    time_elapsed     | 646      |\n",
      "|    total_timesteps  | 382120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.117    |\n",
      "|    n_updates        | 105425   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 797      |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 520      |\n",
      "|    fps              | 590      |\n",
      "|    time_elapsed     | 656      |\n",
      "|    total_timesteps  | 387312   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 105430   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 810      |\n",
      "|    ep_rew_mean      | 4.49     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 524      |\n",
      "|    fps              | 590      |\n",
      "|    time_elapsed     | 660      |\n",
      "|    total_timesteps  | 389968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 105432   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 815      |\n",
      "|    ep_rew_mean      | 4.33     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 528      |\n",
      "|    fps              | 590      |\n",
      "|    time_elapsed     | 665      |\n",
      "|    total_timesteps  | 392648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.108    |\n",
      "|    n_updates        | 105435   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 816      |\n",
      "|    ep_rew_mean      | 3.98     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 532      |\n",
      "|    fps              | 590      |\n",
      "|    time_elapsed     | 669      |\n",
      "|    total_timesteps  | 395136   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.628    |\n",
      "|    n_updates        | 105437   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 812      |\n",
      "|    ep_rew_mean      | 4.06     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 536      |\n",
      "|    fps              | 590      |\n",
      "|    time_elapsed     | 674      |\n",
      "|    total_timesteps  | 397824   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.11     |\n",
      "|    n_updates        | 105440   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 816      |\n",
      "|    ep_rew_mean      | 7.09     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 540      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 677      |\n",
      "|    total_timesteps  | 399928   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.1      |\n",
      "|    n_updates        | 105442   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 807      |\n",
      "|    ep_rew_mean      | 6.26     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 544      |\n",
      "|    fps              | 589      |\n",
      "|    time_elapsed     | 682      |\n",
      "|    total_timesteps  | 401960   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.757    |\n",
      "|    n_updates        | 105444   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 795      |\n",
      "|    ep_rew_mean      | 4.42     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 548      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 691      |\n",
      "|    total_timesteps  | 406784   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.109    |\n",
      "|    n_updates        | 105449   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 789      |\n",
      "|    ep_rew_mean      | 6.24     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 552      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 695      |\n",
      "|    total_timesteps  | 409064   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.867    |\n",
      "|    n_updates        | 105451   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 796      |\n",
      "|    ep_rew_mean      | 6.72     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 556      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 699      |\n",
      "|    total_timesteps  | 411656   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.926    |\n",
      "|    n_updates        | 105454   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 778      |\n",
      "|    ep_rew_mean      | 2.06     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 560      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 704      |\n",
      "|    total_timesteps  | 414688   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0617   |\n",
      "|    n_updates        | 105456   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 761      |\n",
      "|    ep_rew_mean      | -0.25    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 564      |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 710      |\n",
      "|    total_timesteps  | 417440   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.044    |\n",
      "|    n_updates        | 105459   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 745      |\n",
      "|    ep_rew_mean      | -1.21    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 568      |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 717      |\n",
      "|    total_timesteps  | 421376   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0861   |\n",
      "|    n_updates        | 105463   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 747      |\n",
      "|    ep_rew_mean      | -2.27    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 572      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 721      |\n",
      "|    total_timesteps  | 423376   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0311   |\n",
      "|    n_updates        | 105465   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 725      |\n",
      "|    ep_rew_mean      | -6.38    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 576      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 726      |\n",
      "|    total_timesteps  | 425992   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0791   |\n",
      "|    n_updates        | 105468   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 730      |\n",
      "|    ep_rew_mean      | -4.53    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 580      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 732      |\n",
      "|    total_timesteps  | 430080   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00655  |\n",
      "|    n_updates        | 105471   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 740      |\n",
      "|    ep_rew_mean      | -3.82    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 584      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 736      |\n",
      "|    total_timesteps  | 431544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0964   |\n",
      "|    n_updates        | 105473   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 732      |\n",
      "|    ep_rew_mean      | -4.68    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 588      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 740      |\n",
      "|    total_timesteps  | 433752   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.151    |\n",
      "|    n_updates        | 105475   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 713      |\n",
      "|    ep_rew_mean      | -6.19    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 592      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 745      |\n",
      "|    total_timesteps  | 437272   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.122    |\n",
      "|    n_updates        | 105479   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 717      |\n",
      "|    ep_rew_mean      | -6.88    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 596      |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 748      |\n",
      "|    total_timesteps  | 440048   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.116    |\n",
      "|    n_updates        | 105481   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 718      |\n",
      "|    ep_rew_mean      | -5.35    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 600      |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 753      |\n",
      "|    total_timesteps  | 442392   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.14     |\n",
      "|    n_updates        | 105484   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 722      |\n",
      "|    ep_rew_mean      | -3.15    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 604      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 759      |\n",
      "|    total_timesteps  | 445272   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0102   |\n",
      "|    n_updates        | 105486   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 733      |\n",
      "|    ep_rew_mean      | -1.93    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 608      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 769      |\n",
      "|    total_timesteps  | 450816   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.13     |\n",
      "|    n_updates        | 105492   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 737      |\n",
      "|    ep_rew_mean      | -0.11    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 612      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 774      |\n",
      "|    total_timesteps  | 453288   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0375   |\n",
      "|    n_updates        | 105494   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 734      |\n",
      "|    ep_rew_mean      | -0.15    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 616      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 780      |\n",
      "|    total_timesteps  | 456824   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.633    |\n",
      "|    n_updates        | 105498   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 749      |\n",
      "|    ep_rew_mean      | 2.45     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 620      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 787      |\n",
      "|    total_timesteps  | 460776   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.49     |\n",
      "|    n_updates        | 105501   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 740      |\n",
      "|    ep_rew_mean      | -0.88    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 624      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 791      |\n",
      "|    total_timesteps  | 463504   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 105504   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 732      |\n",
      "|    ep_rew_mean      | -2.16    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 628      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 796      |\n",
      "|    total_timesteps  | 467296   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0732   |\n",
      "|    n_updates        | 105508   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 741      |\n",
      "|    ep_rew_mean      | -3.29    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 632      |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 800      |\n",
      "|    total_timesteps  | 470272   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0856   |\n",
      "|    n_updates        | 105511   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 747      |\n",
      "|    ep_rew_mean      | -2.88    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 636      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 804      |\n",
      "|    total_timesteps  | 473424   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0658   |\n",
      "|    n_updates        | 105514   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 750      |\n",
      "|    ep_rew_mean      | -5.63    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 640      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 813      |\n",
      "|    total_timesteps  | 478512   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 105519   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 756      |\n",
      "|    ep_rew_mean      | -5.74    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 644      |\n",
      "|    fps              | 588      |\n",
      "|    time_elapsed     | 817      |\n",
      "|    total_timesteps  | 481160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0141   |\n",
      "|    n_updates        | 105521   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 752      |\n",
      "|    ep_rew_mean      | -4.96    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 648      |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 824      |\n",
      "|    total_timesteps  | 484544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0998   |\n",
      "|    n_updates        | 105525   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 771      |\n",
      "|    ep_rew_mean      | -4.97    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 652      |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 830      |\n",
      "|    total_timesteps  | 487856   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0524   |\n",
      "|    n_updates        | 105528   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 791      |\n",
      "|    ep_rew_mean      | -2.35    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 656      |\n",
      "|    fps              | 587      |\n",
      "|    time_elapsed     | 836      |\n",
      "|    total_timesteps  | 491304   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0833   |\n",
      "|    n_updates        | 105531   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 788      |\n",
      "|    ep_rew_mean      | -4.59    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 660      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 841      |\n",
      "|    total_timesteps  | 493784   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.208    |\n",
      "|    n_updates        | 105534   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 787      |\n",
      "|    ep_rew_mean      | -6.21    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 664      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 849      |\n",
      "|    total_timesteps  | 497752   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0515   |\n",
      "|    n_updates        | 105538   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 800      |\n",
      "|    ep_rew_mean      | -3.55    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 668      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 854      |\n",
      "|    total_timesteps  | 500896   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 105541   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 803      |\n",
      "|    ep_rew_mean      | -1.05    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 672      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 861      |\n",
      "|    total_timesteps  | 504832   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0524   |\n",
      "|    n_updates        | 105544   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 804      |\n",
      "|    ep_rew_mean      | 0.44     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 676      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 864      |\n",
      "|    total_timesteps  | 506608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0111   |\n",
      "|    n_updates        | 105546   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 811      |\n",
      "|    ep_rew_mean      | -0.67    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 680      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 874      |\n",
      "|    total_timesteps  | 511744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.128    |\n",
      "|    n_updates        | 105551   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 820      |\n",
      "|    ep_rew_mean      | 0.77     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 684      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 879      |\n",
      "|    total_timesteps  | 514664   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.103    |\n",
      "|    n_updates        | 105554   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 814      |\n",
      "|    ep_rew_mean      | 0.76     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 688      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 882      |\n",
      "|    total_timesteps  | 516344   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0504   |\n",
      "|    n_updates        | 105556   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 826      |\n",
      "|    ep_rew_mean      | 4.12     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 692      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 889      |\n",
      "|    total_timesteps  | 520232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0439   |\n",
      "|    n_updates        | 105560   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 834      |\n",
      "|    ep_rew_mean      | 7.27     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 696      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 893      |\n",
      "|    total_timesteps  | 522824   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00383  |\n",
      "|    n_updates        | 105562   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 832      |\n",
      "|    ep_rew_mean      | 6.47     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 700      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 900      |\n",
      "|    total_timesteps  | 526656   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.654    |\n",
      "|    n_updates        | 105566   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 835      |\n",
      "|    ep_rew_mean      | 5.58     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 704      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 904      |\n",
      "|    total_timesteps  | 528968   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0466   |\n",
      "|    n_updates        | 105568   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 827      |\n",
      "|    ep_rew_mean      | 6.03     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 708      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 908      |\n",
      "|    total_timesteps  | 531944   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.078    |\n",
      "|    n_updates        | 105571   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 819      |\n",
      "|    ep_rew_mean      | 4.76     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 712      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 914      |\n",
      "|    total_timesteps  | 535912   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0112   |\n",
      "|    n_updates        | 105575   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 831      |\n",
      "|    ep_rew_mean      | 4.54     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 716      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 921      |\n",
      "|    total_timesteps  | 539712   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.077    |\n",
      "|    n_updates        | 105579   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 813      |\n",
      "|    ep_rew_mean      | 0.03     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 720      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 928      |\n",
      "|    total_timesteps  | 544448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.115    |\n",
      "|    n_updates        | 105583   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 833      |\n",
      "|    ep_rew_mean      | 2.29     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 724      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 934      |\n",
      "|    total_timesteps  | 547784   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.694    |\n",
      "|    n_updates        | 105586   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 835      |\n",
      "|    ep_rew_mean      | 2.8      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 728      |\n",
      "|    fps              | 586      |\n",
      "|    time_elapsed     | 938      |\n",
      "|    total_timesteps  | 550208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.667    |\n",
      "|    n_updates        | 105589   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 836      |\n",
      "|    ep_rew_mean      | 5.35     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 732      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 942      |\n",
      "|    total_timesteps  | 552400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0773   |\n",
      "|    n_updates        | 105591   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 832      |\n",
      "|    ep_rew_mean      | 3.95     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 736      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 948      |\n",
      "|    total_timesteps  | 555600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.088    |\n",
      "|    n_updates        | 105594   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 822      |\n",
      "|    ep_rew_mean      | 2.37     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 740      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 952      |\n",
      "|    total_timesteps  | 557992   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0755   |\n",
      "|    n_updates        | 105596   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 819      |\n",
      "|    ep_rew_mean      | 2.44     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 744      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 957      |\n",
      "|    total_timesteps  | 560840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.014    |\n",
      "|    n_updates        | 105599   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 825      |\n",
      "|    ep_rew_mean      | 1.9      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 748      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 960      |\n",
      "|    total_timesteps  | 562016   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.174    |\n",
      "|    n_updates        | 105600   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 797      |\n",
      "|    ep_rew_mean      | 0.19     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 752      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 968      |\n",
      "|    total_timesteps  | 566880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.118    |\n",
      "|    n_updates        | 105605   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 788      |\n",
      "|    ep_rew_mean      | 0.51     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 756      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 974      |\n",
      "|    total_timesteps  | 569664   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0319   |\n",
      "|    n_updates        | 105608   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 785      |\n",
      "|    ep_rew_mean      | 0.83     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 760      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 979      |\n",
      "|    total_timesteps  | 572728   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0231   |\n",
      "|    n_updates        | 105611   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 799      |\n",
      "|    ep_rew_mean      | 5.09     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 764      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 984      |\n",
      "|    total_timesteps  | 575416   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.141    |\n",
      "|    n_updates        | 105613   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 785      |\n",
      "|    ep_rew_mean      | 3.74     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 768      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 991      |\n",
      "|    total_timesteps  | 579232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0451   |\n",
      "|    n_updates        | 105617   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 778      |\n",
      "|    ep_rew_mean      | 1.54     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 772      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 997      |\n",
      "|    total_timesteps  | 582688   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.354    |\n",
      "|    n_updates        | 105621   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 780      |\n",
      "|    ep_rew_mean      | 1.1      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 776      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 1002     |\n",
      "|    total_timesteps  | 586104   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0595   |\n",
      "|    n_updates        | 105624   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 779      |\n",
      "|    ep_rew_mean      | 2.89     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 780      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 1005     |\n",
      "|    total_timesteps  | 588008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0742   |\n",
      "|    n_updates        | 105626   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 771      |\n",
      "|    ep_rew_mean      | 3.14     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 784      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 1009     |\n",
      "|    total_timesteps  | 590920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0438   |\n",
      "|    n_updates        | 105629   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 773      |\n",
      "|    ep_rew_mean      | 4.46     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 788      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 1014     |\n",
      "|    total_timesteps  | 594112   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 105632   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 773      |\n",
      "|    ep_rew_mean      | 3.24     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 792      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 1020     |\n",
      "|    total_timesteps  | 597448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.153    |\n",
      "|    n_updates        | 105635   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 777      |\n",
      "|    ep_rew_mean      | 4.68     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 796      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 1027     |\n",
      "|    total_timesteps  | 601688   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0124   |\n",
      "|    n_updates        | 105639   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 783      |\n",
      "|    ep_rew_mean      | 5.93     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 800      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 1028     |\n",
      "|    total_timesteps  | 602648   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0383   |\n",
      "|    n_updates        | 105640   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 779      |\n",
      "|    ep_rew_mean      | 4.26     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 804      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 1037     |\n",
      "|    total_timesteps  | 608208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0836   |\n",
      "|    n_updates        | 105645   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 785      |\n",
      "|    ep_rew_mean      | 4.96     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 808      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 1042     |\n",
      "|    total_timesteps  | 610448   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0565   |\n",
      "|    n_updates        | 105648   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 785      |\n",
      "|    ep_rew_mean      | 4.75     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 812      |\n",
      "|    fps              | 585      |\n",
      "|    time_elapsed     | 1047     |\n",
      "|    total_timesteps  | 613544   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.119    |\n",
      "|    n_updates        | 105651   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 777      |\n",
      "|    ep_rew_mean      | 5.08     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 816      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 1056     |\n",
      "|    total_timesteps  | 617912   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.123    |\n",
      "|    n_updates        | 105655   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 788      |\n",
      "|    ep_rew_mean      | 4.28     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 820      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 1063     |\n",
      "|    total_timesteps  | 622120   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 105659   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 782      |\n",
      "|    ep_rew_mean      | 2.62     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 824      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 1070     |\n",
      "|    total_timesteps  | 625392   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.673    |\n",
      "|    n_updates        | 105662   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 793      |\n",
      "|    ep_rew_mean      | 3.46     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 828      |\n",
      "|    fps              | 584      |\n",
      "|    time_elapsed     | 1077     |\n",
      "|    total_timesteps  | 629304   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0525   |\n",
      "|    n_updates        | 105666   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 781      |\n",
      "|    ep_rew_mean      | 2.91     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 832      |\n",
      "|    fps              | 583      |\n",
      "|    time_elapsed     | 1080     |\n",
      "|    total_timesteps  | 630976   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0429   |\n",
      "|    n_updates        | 105668   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 786      |\n",
      "|    ep_rew_mean      | 5.7      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 836      |\n",
      "|    fps              | 583      |\n",
      "|    time_elapsed     | 1087     |\n",
      "|    total_timesteps  | 634152   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00674  |\n",
      "|    n_updates        | 105671   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 791      |\n",
      "|    ep_rew_mean      | 6.02     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 840      |\n",
      "|    fps              | 582      |\n",
      "|    time_elapsed     | 1095     |\n",
      "|    total_timesteps  | 637800   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0346   |\n",
      "|    n_updates        | 105674   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 793      |\n",
      "|    ep_rew_mean      | 6.87     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 844      |\n",
      "|    fps              | 581      |\n",
      "|    time_elapsed     | 1102     |\n",
      "|    total_timesteps  | 640552   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 105677   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 797      |\n",
      "|    ep_rew_mean      | 8.16     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 848      |\n",
      "|    fps              | 580      |\n",
      "|    time_elapsed     | 1106     |\n",
      "|    total_timesteps  | 642976   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0739   |\n",
      "|    n_updates        | 105679   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 798      |\n",
      "|    ep_rew_mean      | 7.36     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 852      |\n",
      "|    fps              | 580      |\n",
      "|    time_elapsed     | 1110     |\n",
      "|    total_timesteps  | 644888   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0832   |\n",
      "|    n_updates        | 105681   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 779      |\n",
      "|    ep_rew_mean      | 5.25     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 856      |\n",
      "|    fps              | 581      |\n",
      "|    time_elapsed     | 1113     |\n",
      "|    total_timesteps  | 647424   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.08     |\n",
      "|    n_updates        | 105684   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 778      |\n",
      "|    ep_rew_mean      | 5.25     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 860      |\n",
      "|    fps              | 581      |\n",
      "|    time_elapsed     | 1116     |\n",
      "|    total_timesteps  | 649520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0794   |\n",
      "|    n_updates        | 105686   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 764      |\n",
      "|    ep_rew_mean      | 1.1      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 864      |\n",
      "|    fps              | 581      |\n",
      "|    time_elapsed     | 1122     |\n",
      "|    total_timesteps  | 653160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.151    |\n",
      "|    n_updates        | 105689   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 766      |\n",
      "|    ep_rew_mean      | 0.21     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 868      |\n",
      "|    fps              | 581      |\n",
      "|    time_elapsed     | 1126     |\n",
      "|    total_timesteps  | 655184   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.134    |\n",
      "|    n_updates        | 105691   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 764      |\n",
      "|    ep_rew_mean      | -0.37    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 872      |\n",
      "|    fps              | 581      |\n",
      "|    time_elapsed     | 1131     |\n",
      "|    total_timesteps  | 658176   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.113    |\n",
      "|    n_updates        | 105694   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 757      |\n",
      "|    ep_rew_mean      | -0.72    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 876      |\n",
      "|    fps              | 581      |\n",
      "|    time_elapsed     | 1141     |\n",
      "|    total_timesteps  | 663920   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0388   |\n",
      "|    n_updates        | 105700   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 773      |\n",
      "|    ep_rew_mean      | -3.27    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 880      |\n",
      "|    fps              | 581      |\n",
      "|    time_elapsed     | 1143     |\n",
      "|    total_timesteps  | 665224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0326   |\n",
      "|    n_updates        | 105701   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 775      |\n",
      "|    ep_rew_mean      | -5.01    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 884      |\n",
      "|    fps              | 581      |\n",
      "|    time_elapsed     | 1152     |\n",
      "|    total_timesteps  | 669952   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0282   |\n",
      "|    n_updates        | 105706   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 789      |\n",
      "|    ep_rew_mean      | -4.61    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 888      |\n",
      "|    fps              | 580      |\n",
      "|    time_elapsed     | 1160     |\n",
      "|    total_timesteps  | 673816   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0688   |\n",
      "|    n_updates        | 105710   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 805      |\n",
      "|    ep_rew_mean      | -3.43    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 892      |\n",
      "|    fps              | 580      |\n",
      "|    time_elapsed     | 1170     |\n",
      "|    total_timesteps  | 679568   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 105715   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 815      |\n",
      "|    ep_rew_mean      | -1.69    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 896      |\n",
      "|    fps              | 580      |\n",
      "|    time_elapsed     | 1176     |\n",
      "|    total_timesteps  | 682760   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0479   |\n",
      "|    n_updates        | 105718   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 817      |\n",
      "|    ep_rew_mean      | -3.34    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 900      |\n",
      "|    fps              | 579      |\n",
      "|    time_elapsed     | 1189     |\n",
      "|    total_timesteps  | 689336   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.021    |\n",
      "|    n_updates        | 105725   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 846      |\n",
      "|    ep_rew_mean      | -0.76    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 904      |\n",
      "|    fps              | 579      |\n",
      "|    time_elapsed     | 1195     |\n",
      "|    total_timesteps  | 692520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.15     |\n",
      "|    n_updates        | 105728   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 843      |\n",
      "|    ep_rew_mean      | -0.81    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 908      |\n",
      "|    fps              | 579      |\n",
      "|    time_elapsed     | 1201     |\n",
      "|    total_timesteps  | 696096   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0465   |\n",
      "|    n_updates        | 105731   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 845      |\n",
      "|    ep_rew_mean      | -0.87    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 912      |\n",
      "|    fps              | 579      |\n",
      "|    time_elapsed     | 1205     |\n",
      "|    total_timesteps  | 698272   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0168   |\n",
      "|    n_updates        | 105733   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 849      |\n",
      "|    ep_rew_mean      | -1.57    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 916      |\n",
      "|    fps              | 579      |\n",
      "|    time_elapsed     | 1209     |\n",
      "|    total_timesteps  | 700640   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.149    |\n",
      "|    n_updates        | 105736   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 828      |\n",
      "|    ep_rew_mean      | -2.11    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 920      |\n",
      "|    fps              | 578      |\n",
      "|    time_elapsed     | 1215     |\n",
      "|    total_timesteps  | 703024   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0965   |\n",
      "|    n_updates        | 105738   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 829      |\n",
      "|    ep_rew_mean      | -1.6     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 924      |\n",
      "|    fps              | 577      |\n",
      "|    time_elapsed     | 1225     |\n",
      "|    total_timesteps  | 707984   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.106    |\n",
      "|    n_updates        | 105743   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 830      |\n",
      "|    ep_rew_mean      | -1.18    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 928      |\n",
      "|    fps              | 577      |\n",
      "|    time_elapsed     | 1230     |\n",
      "|    total_timesteps  | 710736   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0598   |\n",
      "|    n_updates        | 105746   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 829      |\n",
      "|    ep_rew_mean      | -2.15    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 932      |\n",
      "|    fps              | 576      |\n",
      "|    time_elapsed     | 1239     |\n",
      "|    total_timesteps  | 714328   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.808    |\n",
      "|    n_updates        | 105749   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 828      |\n",
      "|    ep_rew_mean      | -4.88    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 936      |\n",
      "|    fps              | 574      |\n",
      "|    time_elapsed     | 1248     |\n",
      "|    total_timesteps  | 717232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0608   |\n",
      "|    n_updates        | 105752   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 827      |\n",
      "|    ep_rew_mean      | -3.99    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 940      |\n",
      "|    fps              | 573      |\n",
      "|    time_elapsed     | 1258     |\n",
      "|    total_timesteps  | 721912   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0526   |\n",
      "|    n_updates        | 105756   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 847      |\n",
      "|    ep_rew_mean      | 2.08     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 944      |\n",
      "|    fps              | 573      |\n",
      "|    time_elapsed     | 1263     |\n",
      "|    total_timesteps  | 724504   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.167    |\n",
      "|    n_updates        | 105759   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 843      |\n",
      "|    ep_rew_mean      | -1.07    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 948      |\n",
      "|    fps              | 573      |\n",
      "|    time_elapsed     | 1269     |\n",
      "|    total_timesteps  | 727832   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.673    |\n",
      "|    n_updates        | 105762   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 838      |\n",
      "|    ep_rew_mean      | -0.94    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 952      |\n",
      "|    fps              | 573      |\n",
      "|    time_elapsed     | 1276     |\n",
      "|    total_timesteps  | 731408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.16     |\n",
      "|    n_updates        | 105766   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 849      |\n",
      "|    ep_rew_mean      | 1.91     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 956      |\n",
      "|    fps              | 573      |\n",
      "|    time_elapsed     | 1279     |\n",
      "|    total_timesteps  | 733208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0213   |\n",
      "|    n_updates        | 105768   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 863      |\n",
      "|    ep_rew_mean      | 3.64     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 960      |\n",
      "|    fps              | 572      |\n",
      "|    time_elapsed     | 1284     |\n",
      "|    total_timesteps  | 735776   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.152    |\n",
      "|    n_updates        | 105770   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 860      |\n",
      "|    ep_rew_mean      | 4.82     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 964      |\n",
      "|    fps              | 572      |\n",
      "|    time_elapsed     | 1289     |\n",
      "|    total_timesteps  | 738704   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00879  |\n",
      "|    n_updates        | 105773   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 862      |\n",
      "|    ep_rew_mean      | 4.93     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 968      |\n",
      "|    fps              | 572      |\n",
      "|    time_elapsed     | 1294     |\n",
      "|    total_timesteps  | 741528   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0829   |\n",
      "|    n_updates        | 105776   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 869      |\n",
      "|    ep_rew_mean      | 7.67     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 972      |\n",
      "|    fps              | 572      |\n",
      "|    time_elapsed     | 1299     |\n",
      "|    total_timesteps  | 743952   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0594   |\n",
      "|    n_updates        | 105778   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 861      |\n",
      "|    ep_rew_mean      | 5.53     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 976      |\n",
      "|    fps              | 572      |\n",
      "|    time_elapsed     | 1301     |\n",
      "|    total_timesteps  | 745104   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0959   |\n",
      "|    n_updates        | 105779   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 835      |\n",
      "|    ep_rew_mean      | 4.6      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 980      |\n",
      "|    fps              | 572      |\n",
      "|    time_elapsed     | 1307     |\n",
      "|    total_timesteps  | 748608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0153   |\n",
      "|    n_updates        | 105783   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 832      |\n",
      "|    ep_rew_mean      | 5.56     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 984      |\n",
      "|    fps              | 572      |\n",
      "|    time_elapsed     | 1312     |\n",
      "|    total_timesteps  | 751600   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.032    |\n",
      "|    n_updates        | 105785   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 827      |\n",
      "|    ep_rew_mean      | 4.19     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 988      |\n",
      "|    fps              | 572      |\n",
      "|    time_elapsed     | 1320     |\n",
      "|    total_timesteps  | 755704   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0148   |\n",
      "|    n_updates        | 105789   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 801      |\n",
      "|    ep_rew_mean      | 2.1      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 992      |\n",
      "|    fps              | 571      |\n",
      "|    time_elapsed     | 1326     |\n",
      "|    total_timesteps  | 758408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0592   |\n",
      "|    n_updates        | 105792   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 785      |\n",
      "|    ep_rew_mean      | -0.95    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 996      |\n",
      "|    fps              | 570      |\n",
      "|    time_elapsed     | 1333     |\n",
      "|    total_timesteps  | 761136   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0236   |\n",
      "|    n_updates        | 105795   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 790      |\n",
      "|    ep_rew_mean      | 0.19     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1000     |\n",
      "|    fps              | 569      |\n",
      "|    time_elapsed     | 1341     |\n",
      "|    total_timesteps  | 764280   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.19     |\n",
      "|    n_updates        | 105798   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 762      |\n",
      "|    ep_rew_mean      | -2.31    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1004     |\n",
      "|    fps              | 569      |\n",
      "|    time_elapsed     | 1347     |\n",
      "|    total_timesteps  | 767472   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0509   |\n",
      "|    n_updates        | 105801   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 767      |\n",
      "|    ep_rew_mean      | -3.87    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1008     |\n",
      "|    fps              | 569      |\n",
      "|    time_elapsed     | 1360     |\n",
      "|    total_timesteps  | 774480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.102    |\n",
      "|    n_updates        | 105808   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 772      |\n",
      "|    ep_rew_mean      | -1.91    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1012     |\n",
      "|    fps              | 569      |\n",
      "|    time_elapsed     | 1363     |\n",
      "|    total_timesteps  | 776232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.113    |\n",
      "|    n_updates        | 105810   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 774      |\n",
      "|    ep_rew_mean      | -2.94    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1016     |\n",
      "|    fps              | 568      |\n",
      "|    time_elapsed     | 1370     |\n",
      "|    total_timesteps  | 779688   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0219   |\n",
      "|    n_updates        | 105813   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 792      |\n",
      "|    ep_rew_mean      | -1.06    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1020     |\n",
      "|    fps              | 569      |\n",
      "|    time_elapsed     | 1376     |\n",
      "|    total_timesteps  | 783408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0201   |\n",
      "|    n_updates        | 105817   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 774      |\n",
      "|    ep_rew_mean      | -3.09    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1024     |\n",
      "|    fps              | 569      |\n",
      "|    time_elapsed     | 1381     |\n",
      "|    total_timesteps  | 786208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0861   |\n",
      "|    n_updates        | 105819   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 778      |\n",
      "|    ep_rew_mean      | -3       |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1028     |\n",
      "|    fps              | 568      |\n",
      "|    time_elapsed     | 1387     |\n",
      "|    total_timesteps  | 789592   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0382   |\n",
      "|    n_updates        | 105823   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 781      |\n",
      "|    ep_rew_mean      | -2.4     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1032     |\n",
      "|    fps              | 568      |\n",
      "|    time_elapsed     | 1394     |\n",
      "|    total_timesteps  | 792576   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.12     |\n",
      "|    n_updates        | 105825   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 779      |\n",
      "|    ep_rew_mean      | 0.9      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1036     |\n",
      "|    fps              | 568      |\n",
      "|    time_elapsed     | 1401     |\n",
      "|    total_timesteps  | 796216   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.157    |\n",
      "|    n_updates        | 105829   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 786      |\n",
      "|    ep_rew_mean      | 3.21     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1040     |\n",
      "|    fps              | 568      |\n",
      "|    time_elapsed     | 1406     |\n",
      "|    total_timesteps  | 799168   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.156    |\n",
      "|    n_updates        | 105832   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 769      |\n",
      "|    ep_rew_mean      | -2.47    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1044     |\n",
      "|    fps              | 567      |\n",
      "|    time_elapsed     | 1412     |\n",
      "|    total_timesteps  | 801904   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0472   |\n",
      "|    n_updates        | 105835   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 770      |\n",
      "|    ep_rew_mean      | -1.17    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1048     |\n",
      "|    fps              | 568      |\n",
      "|    time_elapsed     | 1420     |\n",
      "|    total_timesteps  | 806840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0553   |\n",
      "|    n_updates        | 105839   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 793      |\n",
      "|    ep_rew_mean      | 0.86     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1052     |\n",
      "|    fps              | 567      |\n",
      "|    time_elapsed     | 1425     |\n",
      "|    total_timesteps  | 809520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.101    |\n",
      "|    n_updates        | 105842   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 797      |\n",
      "|    ep_rew_mean      | -1.43    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1056     |\n",
      "|    fps              | 567      |\n",
      "|    time_elapsed     | 1431     |\n",
      "|    total_timesteps  | 812624   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.865    |\n",
      "|    n_updates        | 105845   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 795      |\n",
      "|    ep_rew_mean      | 0.04     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1060     |\n",
      "|    fps              | 567      |\n",
      "|    time_elapsed     | 1439     |\n",
      "|    total_timesteps  | 816832   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.186    |\n",
      "|    n_updates        | 105849   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 809      |\n",
      "|    ep_rew_mean      | -0.24    |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1064     |\n",
      "|    fps              | 567      |\n",
      "|    time_elapsed     | 1445     |\n",
      "|    total_timesteps  | 820040   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0936   |\n",
      "|    n_updates        | 105852   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 814      |\n",
      "|    ep_rew_mean      | 1.26     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1068     |\n",
      "|    fps              | 566      |\n",
      "|    time_elapsed     | 1455     |\n",
      "|    total_timesteps  | 824984   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0717   |\n",
      "|    n_updates        | 105857   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 831      |\n",
      "|    ep_rew_mean      | 1.6      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1072     |\n",
      "|    fps              | 566      |\n",
      "|    time_elapsed     | 1461     |\n",
      "|    total_timesteps  | 828248   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0528   |\n",
      "|    n_updates        | 105860   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 847      |\n",
      "|    ep_rew_mean      | 1.9      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1076     |\n",
      "|    fps              | 566      |\n",
      "|    time_elapsed     | 1467     |\n",
      "|    total_timesteps  | 831496   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.08     |\n",
      "|    n_updates        | 105864   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 861      |\n",
      "|    ep_rew_mean      | 4.39     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1080     |\n",
      "|    fps              | 566      |\n",
      "|    time_elapsed     | 1479     |\n",
      "|    total_timesteps  | 837608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0415   |\n",
      "|    n_updates        | 105869   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 870      |\n",
      "|    ep_rew_mean      | 3.5      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1084     |\n",
      "|    fps              | 565      |\n",
      "|    time_elapsed     | 1484     |\n",
      "|    total_timesteps  | 839416   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.714    |\n",
      "|    n_updates        | 105871   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 868      |\n",
      "|    ep_rew_mean      | 4.2      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1088     |\n",
      "|    fps              | 565      |\n",
      "|    time_elapsed     | 1489     |\n",
      "|    total_timesteps  | 841888   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0427   |\n",
      "|    n_updates        | 105874   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 870      |\n",
      "|    ep_rew_mean      | 4.54     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1092     |\n",
      "|    fps              | 565      |\n",
      "|    time_elapsed     | 1494     |\n",
      "|    total_timesteps  | 844744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0695   |\n",
      "|    n_updates        | 105876   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 873      |\n",
      "|    ep_rew_mean      | 4.08     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1096     |\n",
      "|    fps              | 565      |\n",
      "|    time_elapsed     | 1500     |\n",
      "|    total_timesteps  | 848072   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0248   |\n",
      "|    n_updates        | 105880   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 871      |\n",
      "|    ep_rew_mean      | 2.28     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1100     |\n",
      "|    fps              | 565      |\n",
      "|    time_elapsed     | 1509     |\n",
      "|    total_timesteps  | 853232   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.158    |\n",
      "|    n_updates        | 105885   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 878      |\n",
      "|    ep_rew_mean      | 4.85     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1104     |\n",
      "|    fps              | 564      |\n",
      "|    time_elapsed     | 1515     |\n",
      "|    total_timesteps  | 856160   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0897   |\n",
      "|    n_updates        | 105888   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 871      |\n",
      "|    ep_rew_mean      | 4.08     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1108     |\n",
      "|    fps              | 564      |\n",
      "|    time_elapsed     | 1520     |\n",
      "|    total_timesteps  | 858848   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.676    |\n",
      "|    n_updates        | 105890   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 859      |\n",
      "|    ep_rew_mean      | 1.17     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1112     |\n",
      "|    fps              | 565      |\n",
      "|    time_elapsed     | 1525     |\n",
      "|    total_timesteps  | 862064   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0711   |\n",
      "|    n_updates        | 105893   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 864      |\n",
      "|    ep_rew_mean      | 4.34     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1116     |\n",
      "|    fps              | 565      |\n",
      "|    time_elapsed     | 1530     |\n",
      "|    total_timesteps  | 865384   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0548   |\n",
      "|    n_updates        | 105897   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 855      |\n",
      "|    ep_rew_mean      | 3.95     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1120     |\n",
      "|    fps              | 565      |\n",
      "|    time_elapsed     | 1535     |\n",
      "|    total_timesteps  | 868144   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.666    |\n",
      "|    n_updates        | 105899   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 851      |\n",
      "|    ep_rew_mean      | 4.44     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1124     |\n",
      "|    fps              | 565      |\n",
      "|    time_elapsed     | 1538     |\n",
      "|    total_timesteps  | 869376   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.032    |\n",
      "|    n_updates        | 105900   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 841      |\n",
      "|    ep_rew_mean      | 3.32     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1128     |\n",
      "|    fps              | 564      |\n",
      "|    time_elapsed     | 1546     |\n",
      "|    total_timesteps  | 872768   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.159    |\n",
      "|    n_updates        | 105904   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 842      |\n",
      "|    ep_rew_mean      | 4.53     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1132     |\n",
      "|    fps              | 563      |\n",
      "|    time_elapsed     | 1555     |\n",
      "|    total_timesteps  | 877328   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 105908   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 852      |\n",
      "|    ep_rew_mean      | 2.75     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1136     |\n",
      "|    fps              | 563      |\n",
      "|    time_elapsed     | 1564     |\n",
      "|    total_timesteps  | 881880   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00597  |\n",
      "|    n_updates        | 105913   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 856      |\n",
      "|    ep_rew_mean      | 3.48     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1140     |\n",
      "|    fps              | 563      |\n",
      "|    time_elapsed     | 1569     |\n",
      "|    total_timesteps  | 884488   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0144   |\n",
      "|    n_updates        | 105915   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 863      |\n",
      "|    ep_rew_mean      | 5.93     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1144     |\n",
      "|    fps              | 563      |\n",
      "|    time_elapsed     | 1576     |\n",
      "|    total_timesteps  | 888464   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0398   |\n",
      "|    n_updates        | 105919   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 863      |\n",
      "|    ep_rew_mean      | 8.61     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1148     |\n",
      "|    fps              | 563      |\n",
      "|    time_elapsed     | 1578     |\n",
      "|    total_timesteps  | 889672   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0817   |\n",
      "|    n_updates        | 105920   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 839      |\n",
      "|    ep_rew_mean      | 5.9      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1152     |\n",
      "|    fps              | 563      |\n",
      "|    time_elapsed     | 1581     |\n",
      "|    total_timesteps  | 891872   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.142    |\n",
      "|    n_updates        | 105922   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 826      |\n",
      "|    ep_rew_mean      | 4.48     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1156     |\n",
      "|    fps              | 563      |\n",
      "|    time_elapsed     | 1586     |\n",
      "|    total_timesteps  | 894744   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0966   |\n",
      "|    n_updates        | 105925   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 824      |\n",
      "|    ep_rew_mean      | 5.97     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1160     |\n",
      "|    fps              | 563      |\n",
      "|    time_elapsed     | 1594     |\n",
      "|    total_timesteps  | 898536   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.143    |\n",
      "|    n_updates        | 105929   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 820      |\n",
      "|    ep_rew_mean      | 6.31     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1164     |\n",
      "|    fps              | 563      |\n",
      "|    time_elapsed     | 1601     |\n",
      "|    total_timesteps  | 902224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0486   |\n",
      "|    n_updates        | 105933   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 813      |\n",
      "|    ep_rew_mean      | 5.81     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1168     |\n",
      "|    fps              | 563      |\n",
      "|    time_elapsed     | 1603     |\n",
      "|    total_timesteps  | 903400   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.167    |\n",
      "|    n_updates        | 105934   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 795      |\n",
      "|    ep_rew_mean      | 4.26     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1172     |\n",
      "|    fps              | 563      |\n",
      "|    time_elapsed     | 1612     |\n",
      "|    total_timesteps  | 908432   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.144    |\n",
      "|    n_updates        | 105939   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 800      |\n",
      "|    ep_rew_mean      | 8.21     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1176     |\n",
      "|    fps              | 563      |\n",
      "|    time_elapsed     | 1618     |\n",
      "|    total_timesteps  | 911576   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.672    |\n",
      "|    n_updates        | 105942   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 792      |\n",
      "|    ep_rew_mean      | 5.7      |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1180     |\n",
      "|    fps              | 562      |\n",
      "|    time_elapsed     | 1622     |\n",
      "|    total_timesteps  | 912984   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.659    |\n",
      "|    n_updates        | 105943   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 776      |\n",
      "|    ep_rew_mean      | 6.35     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1184     |\n",
      "|    fps              | 562      |\n",
      "|    time_elapsed     | 1628     |\n",
      "|    total_timesteps  | 916088   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.114    |\n",
      "|    n_updates        | 105946   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 769      |\n",
      "|    ep_rew_mean      | 6.42     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1188     |\n",
      "|    fps              | 562      |\n",
      "|    time_elapsed     | 1631     |\n",
      "|    total_timesteps  | 917520   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.171    |\n",
      "|    n_updates        | 105948   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 767      |\n",
      "|    ep_rew_mean      | 5.55     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1192     |\n",
      "|    fps              | 562      |\n",
      "|    time_elapsed     | 1636     |\n",
      "|    total_timesteps  | 920560   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0461   |\n",
      "|    n_updates        | 105950   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 758      |\n",
      "|    ep_rew_mean      | 4.79     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1196     |\n",
      "|    fps              | 562      |\n",
      "|    time_elapsed     | 1642     |\n",
      "|    total_timesteps  | 923472   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0688   |\n",
      "|    n_updates        | 105953   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 755      |\n",
      "|    ep_rew_mean      | 4.55     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1200     |\n",
      "|    fps              | 562      |\n",
      "|    time_elapsed     | 1651     |\n",
      "|    total_timesteps  | 928768   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0883   |\n",
      "|    n_updates        | 105958   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 751      |\n",
      "|    ep_rew_mean      | 1.63     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1204     |\n",
      "|    fps              | 562      |\n",
      "|    time_elapsed     | 1657     |\n",
      "|    total_timesteps  | 932016   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0425   |\n",
      "|    n_updates        | 105962   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 770      |\n",
      "|    ep_rew_mean      | 5.24     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1208     |\n",
      "|    fps              | 562      |\n",
      "|    time_elapsed     | 1664     |\n",
      "|    total_timesteps  | 935864   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0936   |\n",
      "|    n_updates        | 105965   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 775      |\n",
      "|    ep_rew_mean      | 8.21     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1212     |\n",
      "|    fps              | 562      |\n",
      "|    time_elapsed     | 1672     |\n",
      "|    total_timesteps  | 939832   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0553   |\n",
      "|    n_updates        | 105969   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 779      |\n",
      "|    ep_rew_mean      | 11.1     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1216     |\n",
      "|    fps              | 561      |\n",
      "|    time_elapsed     | 1679     |\n",
      "|    total_timesteps  | 944008   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.692    |\n",
      "|    n_updates        | 105973   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 793      |\n",
      "|    ep_rew_mean      | 14.3     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1220     |\n",
      "|    fps              | 562      |\n",
      "|    time_elapsed     | 1687     |\n",
      "|    total_timesteps  | 948656   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.147    |\n",
      "|    n_updates        | 105978   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 810      |\n",
      "|    ep_rew_mean      | 16       |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1224     |\n",
      "|    fps              | 561      |\n",
      "|    time_elapsed     | 1694     |\n",
      "|    total_timesteps  | 952224   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.179    |\n",
      "|    n_updates        | 105981   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 822      |\n",
      "|    ep_rew_mean      | 18.2     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1228     |\n",
      "|    fps              | 561      |\n",
      "|    time_elapsed     | 1700     |\n",
      "|    total_timesteps  | 955480   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00661  |\n",
      "|    n_updates        | 105985   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 826      |\n",
      "|    ep_rew_mean      | 15.7     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1232     |\n",
      "|    fps              | 561      |\n",
      "|    time_elapsed     | 1711     |\n",
      "|    total_timesteps  | 961728   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0389   |\n",
      "|    n_updates        | 105991   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 827      |\n",
      "|    ep_rew_mean      | 15       |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1236     |\n",
      "|    fps              | 561      |\n",
      "|    time_elapsed     | 1714     |\n",
      "|    total_timesteps  | 963128   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0686   |\n",
      "|    n_updates        | 105992   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 823      |\n",
      "|    ep_rew_mean      | 12.8     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1240     |\n",
      "|    fps              | 561      |\n",
      "|    time_elapsed     | 1720     |\n",
      "|    total_timesteps  | 966656   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00814  |\n",
      "|    n_updates        | 105995   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 823      |\n",
      "|    ep_rew_mean      | 15.3     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1244     |\n",
      "|    fps              | 561      |\n",
      "|    time_elapsed     | 1728     |\n",
      "|    total_timesteps  | 970784   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.105    |\n",
      "|    n_updates        | 106000   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 829      |\n",
      "|    ep_rew_mean      | 13.8     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1248     |\n",
      "|    fps              | 561      |\n",
      "|    time_elapsed     | 1736     |\n",
      "|    total_timesteps  | 975208   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0719   |\n",
      "|    n_updates        | 106004   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 848      |\n",
      "|    ep_rew_mean      | 13       |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1252     |\n",
      "|    fps              | 560      |\n",
      "|    time_elapsed     | 1749     |\n",
      "|    total_timesteps  | 980408   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0595   |\n",
      "|    n_updates        | 106009   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 880      |\n",
      "|    ep_rew_mean      | 18       |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1256     |\n",
      "|    fps              | 559      |\n",
      "|    time_elapsed     | 1755     |\n",
      "|    total_timesteps  | 982840   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0024   |\n",
      "|    n_updates        | 106011   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 878      |\n",
      "|    ep_rew_mean      | 15.4     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1260     |\n",
      "|    fps              | 559      |\n",
      "|    time_elapsed     | 1766     |\n",
      "|    total_timesteps  | 987752   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0353   |\n",
      "|    n_updates        | 106016   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 883      |\n",
      "|    ep_rew_mean      | 16.5     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1264     |\n",
      "|    fps              | 558      |\n",
      "|    time_elapsed     | 1772     |\n",
      "|    total_timesteps  | 990608   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.00541  |\n",
      "|    n_updates        | 106019   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 891      |\n",
      "|    ep_rew_mean      | 19.9     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1268     |\n",
      "|    fps              | 558      |\n",
      "|    time_elapsed     | 1779     |\n",
      "|    total_timesteps  | 993488   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.0676   |\n",
      "|    n_updates        | 106022   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 889      |\n",
      "|    ep_rew_mean      | 20.1     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1272     |\n",
      "|    fps              | 558      |\n",
      "|    time_elapsed     | 1783     |\n",
      "|    total_timesteps  | 995624   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.013    |\n",
      "|    n_updates        | 106024   |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 882      |\n",
      "|    ep_rew_mean      | 19.8     |\n",
      "|    exploration_rate | 0.1      |\n",
      "| time/               |          |\n",
      "|    episodes         | 1276     |\n",
      "|    fps              | 557      |\n",
      "|    time_elapsed     | 1791     |\n",
      "|    total_timesteps  | 999656   |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 0.661    |\n",
      "|    n_updates        | 106028   |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Continue training\n",
    "\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n",
    "\n",
    "\n",
    "vec_env = make_vec_env(\n",
    "    lambda: make_env(seed=np.random.randint(0, 5000))(), \n",
    "    n_envs=8\n",
    ")\n",
    "\n",
    "# Reload the saved model\n",
    "model = DQN.load(\n",
    "    \"new_v15_freq64_dqn_galaxian_long.zip\", \n",
    "    env=vec_env, \n",
    "    exploration_initial_eps=0.3,\n",
    "    exploration_final_eps=0.1, \n",
    "    exploration_fraction = 0.3, \n",
    "    learning_starts=20000, \n",
    "    train_freq=(128, 'step')\n",
    "    ) # it acts different wt smaller freq\n",
    "\n",
    "\n",
    "# Define checkpoint callback\n",
    "checkpoint_callback = CheckpointCallback(\n",
    "    save_freq=1000000, \n",
    "    save_path=\"./checkpoints/\",\n",
    "    name_prefix=\"new\"\n",
    ")\n",
    "\n",
    "# Continue training\n",
    "model.learn(total_timesteps=1000000, callback=checkpoint_callback)\n",
    "\n",
    "# Save the retrained model\n",
    "model.save(\"new_v16_dqn_galaxian_long.zip\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\devpa\\anaconda3\\envs\\atari\\lib\\site-packages\\stable_baselines3\\common\\buffers.py:241: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 1.13GB > 0.85GB\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 23, 'frame_number': 23, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 26, 'frame_number': 26, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 29, 'frame_number': 29, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 32, 'frame_number': 32, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 35, 'frame_number': 35, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 38, 'frame_number': 38, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 41, 'frame_number': 41, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 44, 'frame_number': 44, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 47, 'frame_number': 47, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 50, 'frame_number': 50, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 53, 'frame_number': 53, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 56, 'frame_number': 56, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 59, 'frame_number': 59, 'TimeLimit.truncated': False}]\n",
      "Reward: [-10.], info: [{'lives': 3, 'episode_frame_number': 62, 'frame_number': 62, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 65, 'frame_number': 65, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 68, 'frame_number': 68, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 71, 'frame_number': 71, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 74, 'frame_number': 74, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 77, 'frame_number': 77, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 80, 'frame_number': 80, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 83, 'frame_number': 83, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 86, 'frame_number': 86, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 89, 'frame_number': 89, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 92, 'frame_number': 92, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 95, 'frame_number': 95, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 98, 'frame_number': 98, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 101, 'frame_number': 101, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 104, 'frame_number': 104, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 107, 'frame_number': 107, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 110, 'frame_number': 110, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 113, 'frame_number': 113, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 116, 'frame_number': 116, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 119, 'frame_number': 119, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 122, 'frame_number': 122, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 125, 'frame_number': 125, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 128, 'frame_number': 128, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 131, 'frame_number': 131, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 134, 'frame_number': 134, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 137, 'frame_number': 137, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 140, 'frame_number': 140, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 143, 'frame_number': 143, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 146, 'frame_number': 146, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 149, 'frame_number': 149, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 152, 'frame_number': 152, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 155, 'frame_number': 155, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 158, 'frame_number': 158, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 161, 'frame_number': 161, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 164, 'frame_number': 164, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 167, 'frame_number': 167, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 170, 'frame_number': 170, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 3, 'episode_frame_number': 173, 'frame_number': 173, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 176, 'frame_number': 176, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 179, 'frame_number': 179, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 182, 'frame_number': 182, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 185, 'frame_number': 185, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 188, 'frame_number': 188, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 191, 'frame_number': 191, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 194, 'frame_number': 194, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 197, 'frame_number': 197, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 200, 'frame_number': 200, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 203, 'frame_number': 203, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 206, 'frame_number': 206, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 209, 'frame_number': 209, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 212, 'frame_number': 212, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 215, 'frame_number': 215, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 218, 'frame_number': 218, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 221, 'frame_number': 221, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 224, 'frame_number': 224, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 227, 'frame_number': 227, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 230, 'frame_number': 230, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 233, 'frame_number': 233, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 236, 'frame_number': 236, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 3, 'episode_frame_number': 239, 'frame_number': 239, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 242, 'frame_number': 242, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 245, 'frame_number': 245, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 248, 'frame_number': 248, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 251, 'frame_number': 251, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 254, 'frame_number': 254, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 257, 'frame_number': 257, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 260, 'frame_number': 260, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 263, 'frame_number': 263, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 3, 'episode_frame_number': 266, 'frame_number': 266, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 269, 'frame_number': 269, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 272, 'frame_number': 272, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 275, 'frame_number': 275, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 278, 'frame_number': 278, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 281, 'frame_number': 281, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 284, 'frame_number': 284, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 287, 'frame_number': 287, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 290, 'frame_number': 290, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 3, 'episode_frame_number': 293, 'frame_number': 293, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 296, 'frame_number': 296, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 299, 'frame_number': 299, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 302, 'frame_number': 302, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 305, 'frame_number': 305, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 308, 'frame_number': 308, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 311, 'frame_number': 311, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 314, 'frame_number': 314, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 317, 'frame_number': 317, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 320, 'frame_number': 320, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 323, 'frame_number': 323, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 326, 'frame_number': 326, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 329, 'frame_number': 329, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 332, 'frame_number': 332, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 335, 'frame_number': 335, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 338, 'frame_number': 338, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 341, 'frame_number': 341, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 344, 'frame_number': 344, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 347, 'frame_number': 347, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 350, 'frame_number': 350, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 353, 'frame_number': 353, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 356, 'frame_number': 356, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 359, 'frame_number': 359, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 362, 'frame_number': 362, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 365, 'frame_number': 365, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 3, 'episode_frame_number': 368, 'frame_number': 368, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 371, 'frame_number': 371, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 374, 'frame_number': 374, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 377, 'frame_number': 377, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 380, 'frame_number': 380, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 383, 'frame_number': 383, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 386, 'frame_number': 386, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 389, 'frame_number': 389, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 392, 'frame_number': 392, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 395, 'frame_number': 395, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 398, 'frame_number': 398, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 3, 'episode_frame_number': 401, 'frame_number': 401, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 404, 'frame_number': 404, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 407, 'frame_number': 407, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 410, 'frame_number': 410, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 413, 'frame_number': 413, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 416, 'frame_number': 416, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 419, 'frame_number': 419, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 422, 'frame_number': 422, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 425, 'frame_number': 425, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 428, 'frame_number': 428, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 431, 'frame_number': 431, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 434, 'frame_number': 434, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 437, 'frame_number': 437, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 440, 'frame_number': 440, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 443, 'frame_number': 443, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 446, 'frame_number': 446, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 449, 'frame_number': 449, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 452, 'frame_number': 452, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 455, 'frame_number': 455, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 458, 'frame_number': 458, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 461, 'frame_number': 461, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 464, 'frame_number': 464, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 467, 'frame_number': 467, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 470, 'frame_number': 470, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 473, 'frame_number': 473, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 476, 'frame_number': 476, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 479, 'frame_number': 479, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 482, 'frame_number': 482, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 485, 'frame_number': 485, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 488, 'frame_number': 488, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 491, 'frame_number': 491, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 494, 'frame_number': 494, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 497, 'frame_number': 497, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 500, 'frame_number': 500, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 503, 'frame_number': 503, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 506, 'frame_number': 506, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 509, 'frame_number': 509, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 512, 'frame_number': 512, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 3, 'episode_frame_number': 515, 'frame_number': 515, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 518, 'frame_number': 518, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 521, 'frame_number': 521, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 524, 'frame_number': 524, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 527, 'frame_number': 527, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 530, 'frame_number': 530, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 533, 'frame_number': 533, 'TimeLimit.truncated': False}]\n",
      "Reward: [-5.], info: [{'lives': 3, 'episode_frame_number': 536, 'frame_number': 536, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 539, 'frame_number': 539, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 542, 'frame_number': 542, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 545, 'frame_number': 545, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 548, 'frame_number': 548, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 551, 'frame_number': 551, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 554, 'frame_number': 554, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 557, 'frame_number': 557, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 560, 'frame_number': 560, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 563, 'frame_number': 563, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 566, 'frame_number': 566, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 569, 'frame_number': 569, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 572, 'frame_number': 572, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 575, 'frame_number': 575, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 578, 'frame_number': 578, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 581, 'frame_number': 581, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 584, 'frame_number': 584, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 587, 'frame_number': 587, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 590, 'frame_number': 590, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 593, 'frame_number': 593, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 596, 'frame_number': 596, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 599, 'frame_number': 599, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 602, 'frame_number': 602, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 605, 'frame_number': 605, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 608, 'frame_number': 608, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 611, 'frame_number': 611, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 614, 'frame_number': 614, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 617, 'frame_number': 617, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 620, 'frame_number': 620, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 623, 'frame_number': 623, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 626, 'frame_number': 626, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 629, 'frame_number': 629, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 632, 'frame_number': 632, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 635, 'frame_number': 635, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 638, 'frame_number': 638, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 641, 'frame_number': 641, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 644, 'frame_number': 644, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 647, 'frame_number': 647, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 650, 'frame_number': 650, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 653, 'frame_number': 653, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 656, 'frame_number': 656, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 659, 'frame_number': 659, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 662, 'frame_number': 662, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 665, 'frame_number': 665, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 668, 'frame_number': 668, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 671, 'frame_number': 671, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 674, 'frame_number': 674, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 677, 'frame_number': 677, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 680, 'frame_number': 680, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 683, 'frame_number': 683, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 686, 'frame_number': 686, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 689, 'frame_number': 689, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 692, 'frame_number': 692, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 695, 'frame_number': 695, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 698, 'frame_number': 698, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 701, 'frame_number': 701, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 704, 'frame_number': 704, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 707, 'frame_number': 707, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 710, 'frame_number': 710, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 713, 'frame_number': 713, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 716, 'frame_number': 716, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 719, 'frame_number': 719, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 722, 'frame_number': 722, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 725, 'frame_number': 725, 'TimeLimit.truncated': False}]\n",
      "Reward: [-10.], info: [{'lives': 2, 'episode_frame_number': 728, 'frame_number': 728, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 731, 'frame_number': 731, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 734, 'frame_number': 734, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 737, 'frame_number': 737, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 740, 'frame_number': 740, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 743, 'frame_number': 743, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 746, 'frame_number': 746, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 749, 'frame_number': 749, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 752, 'frame_number': 752, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 755, 'frame_number': 755, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 758, 'frame_number': 758, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 761, 'frame_number': 761, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 2, 'episode_frame_number': 764, 'frame_number': 764, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 767, 'frame_number': 767, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 770, 'frame_number': 770, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 773, 'frame_number': 773, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 776, 'frame_number': 776, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 779, 'frame_number': 779, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 782, 'frame_number': 782, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 785, 'frame_number': 785, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 788, 'frame_number': 788, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 791, 'frame_number': 791, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 794, 'frame_number': 794, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 797, 'frame_number': 797, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 800, 'frame_number': 800, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 803, 'frame_number': 803, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 806, 'frame_number': 806, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 809, 'frame_number': 809, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 812, 'frame_number': 812, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 815, 'frame_number': 815, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 818, 'frame_number': 818, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 821, 'frame_number': 821, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 824, 'frame_number': 824, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 827, 'frame_number': 827, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 830, 'frame_number': 830, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 833, 'frame_number': 833, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 2, 'episode_frame_number': 836, 'frame_number': 836, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 839, 'frame_number': 839, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 842, 'frame_number': 842, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 845, 'frame_number': 845, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 848, 'frame_number': 848, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 851, 'frame_number': 851, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 854, 'frame_number': 854, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 857, 'frame_number': 857, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 860, 'frame_number': 860, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 863, 'frame_number': 863, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 2, 'episode_frame_number': 866, 'frame_number': 866, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 869, 'frame_number': 869, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 872, 'frame_number': 872, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 875, 'frame_number': 875, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 878, 'frame_number': 878, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 881, 'frame_number': 881, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 884, 'frame_number': 884, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 887, 'frame_number': 887, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 890, 'frame_number': 890, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 893, 'frame_number': 893, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 896, 'frame_number': 896, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 899, 'frame_number': 899, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 902, 'frame_number': 902, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 905, 'frame_number': 905, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 908, 'frame_number': 908, 'TimeLimit.truncated': False}]\n",
      "Reward: [-5.], info: [{'lives': 2, 'episode_frame_number': 911, 'frame_number': 911, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 914, 'frame_number': 914, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 917, 'frame_number': 917, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 920, 'frame_number': 920, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 923, 'frame_number': 923, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 926, 'frame_number': 926, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 929, 'frame_number': 929, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 932, 'frame_number': 932, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 935, 'frame_number': 935, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 938, 'frame_number': 938, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 941, 'frame_number': 941, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 944, 'frame_number': 944, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 947, 'frame_number': 947, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 950, 'frame_number': 950, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 953, 'frame_number': 953, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 956, 'frame_number': 956, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 959, 'frame_number': 959, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 962, 'frame_number': 962, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 965, 'frame_number': 965, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 968, 'frame_number': 968, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 971, 'frame_number': 971, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 974, 'frame_number': 974, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 977, 'frame_number': 977, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 980, 'frame_number': 980, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 983, 'frame_number': 983, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 986, 'frame_number': 986, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 989, 'frame_number': 989, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 992, 'frame_number': 992, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 995, 'frame_number': 995, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 998, 'frame_number': 998, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1001, 'frame_number': 1001, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1004, 'frame_number': 1004, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1007, 'frame_number': 1007, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1010, 'frame_number': 1010, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1013, 'frame_number': 1013, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1016, 'frame_number': 1016, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1019, 'frame_number': 1019, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1022, 'frame_number': 1022, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1025, 'frame_number': 1025, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1028, 'frame_number': 1028, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1031, 'frame_number': 1031, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1034, 'frame_number': 1034, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1037, 'frame_number': 1037, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1040, 'frame_number': 1040, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1043, 'frame_number': 1043, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1046, 'frame_number': 1046, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1049, 'frame_number': 1049, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1052, 'frame_number': 1052, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1055, 'frame_number': 1055, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1058, 'frame_number': 1058, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1061, 'frame_number': 1061, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1064, 'frame_number': 1064, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1067, 'frame_number': 1067, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1070, 'frame_number': 1070, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1073, 'frame_number': 1073, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1076, 'frame_number': 1076, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1079, 'frame_number': 1079, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1082, 'frame_number': 1082, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1085, 'frame_number': 1085, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1088, 'frame_number': 1088, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1091, 'frame_number': 1091, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1094, 'frame_number': 1094, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1097, 'frame_number': 1097, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1100, 'frame_number': 1100, 'TimeLimit.truncated': False}]\n",
      "Reward: [-10.], info: [{'lives': 1, 'episode_frame_number': 1103, 'frame_number': 1103, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1106, 'frame_number': 1106, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1109, 'frame_number': 1109, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1112, 'frame_number': 1112, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1115, 'frame_number': 1115, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1118, 'frame_number': 1118, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1121, 'frame_number': 1121, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1124, 'frame_number': 1124, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1127, 'frame_number': 1127, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1130, 'frame_number': 1130, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1133, 'frame_number': 1133, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1136, 'frame_number': 1136, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1139, 'frame_number': 1139, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 1, 'episode_frame_number': 1142, 'frame_number': 1142, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1145, 'frame_number': 1145, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1148, 'frame_number': 1148, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1151, 'frame_number': 1151, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1154, 'frame_number': 1154, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1157, 'frame_number': 1157, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1160, 'frame_number': 1160, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1163, 'frame_number': 1163, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1166, 'frame_number': 1166, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1169, 'frame_number': 1169, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 1, 'episode_frame_number': 1172, 'frame_number': 1172, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1175, 'frame_number': 1175, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1178, 'frame_number': 1178, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1181, 'frame_number': 1181, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1184, 'frame_number': 1184, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1187, 'frame_number': 1187, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1190, 'frame_number': 1190, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1193, 'frame_number': 1193, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1196, 'frame_number': 1196, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1199, 'frame_number': 1199, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1202, 'frame_number': 1202, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1205, 'frame_number': 1205, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1208, 'frame_number': 1208, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1211, 'frame_number': 1211, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1214, 'frame_number': 1214, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1217, 'frame_number': 1217, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1220, 'frame_number': 1220, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1223, 'frame_number': 1223, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1226, 'frame_number': 1226, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1229, 'frame_number': 1229, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1232, 'frame_number': 1232, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1235, 'frame_number': 1235, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1238, 'frame_number': 1238, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1241, 'frame_number': 1241, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1244, 'frame_number': 1244, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1247, 'frame_number': 1247, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1250, 'frame_number': 1250, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1253, 'frame_number': 1253, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1256, 'frame_number': 1256, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1259, 'frame_number': 1259, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1262, 'frame_number': 1262, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1265, 'frame_number': 1265, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1268, 'frame_number': 1268, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1271, 'frame_number': 1271, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1274, 'frame_number': 1274, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1277, 'frame_number': 1277, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1280, 'frame_number': 1280, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1283, 'frame_number': 1283, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1286, 'frame_number': 1286, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1289, 'frame_number': 1289, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1292, 'frame_number': 1292, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1295, 'frame_number': 1295, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1298, 'frame_number': 1298, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1301, 'frame_number': 1301, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1304, 'frame_number': 1304, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1307, 'frame_number': 1307, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1310, 'frame_number': 1310, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1313, 'frame_number': 1313, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1316, 'frame_number': 1316, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1319, 'frame_number': 1319, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1322, 'frame_number': 1322, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1325, 'frame_number': 1325, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1328, 'frame_number': 1328, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1331, 'frame_number': 1331, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1334, 'frame_number': 1334, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1337, 'frame_number': 1337, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1340, 'frame_number': 1340, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1343, 'frame_number': 1343, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1346, 'frame_number': 1346, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1349, 'frame_number': 1349, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1352, 'frame_number': 1352, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1355, 'frame_number': 1355, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1358, 'frame_number': 1358, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1361, 'frame_number': 1361, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1364, 'frame_number': 1364, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1367, 'frame_number': 1367, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1370, 'frame_number': 1370, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1373, 'frame_number': 1373, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1376, 'frame_number': 1376, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1379, 'frame_number': 1379, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1382, 'frame_number': 1382, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1385, 'frame_number': 1385, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1388, 'frame_number': 1388, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1391, 'frame_number': 1391, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1394, 'frame_number': 1394, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1397, 'frame_number': 1397, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1400, 'frame_number': 1400, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1403, 'frame_number': 1403, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1406, 'frame_number': 1406, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1409, 'frame_number': 1409, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1412, 'frame_number': 1412, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1415, 'frame_number': 1415, 'TimeLimit.truncated': False}]\n",
      "Reward: [-10.], info: [{'lives': 0, 'episode_frame_number': 1417, 'frame_number': 1417, 'episode': {'r': -38.0, 'l': 466, 't': 27.705751}, 'TimeLimit.truncated': False, 'terminal_observation': array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 4, 'frame_number': 1449, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 7, 'frame_number': 1452, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 10, 'frame_number': 1455, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 13, 'frame_number': 1458, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 16, 'frame_number': 1461, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 19, 'frame_number': 1464, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 22, 'frame_number': 1467, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 25, 'frame_number': 1470, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 28, 'frame_number': 1473, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 31, 'frame_number': 1476, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 34, 'frame_number': 1479, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 37, 'frame_number': 1482, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 40, 'frame_number': 1485, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 43, 'frame_number': 1488, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 46, 'frame_number': 1491, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 49, 'frame_number': 1494, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 52, 'frame_number': 1497, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 55, 'frame_number': 1500, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 58, 'frame_number': 1503, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 61, 'frame_number': 1506, 'TimeLimit.truncated': False}]\n",
      "Reward: [-10.], info: [{'lives': 3, 'episode_frame_number': 64, 'frame_number': 1509, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 67, 'frame_number': 1512, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 70, 'frame_number': 1515, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 73, 'frame_number': 1518, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 76, 'frame_number': 1521, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 79, 'frame_number': 1524, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 82, 'frame_number': 1527, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 85, 'frame_number': 1530, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 88, 'frame_number': 1533, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 91, 'frame_number': 1536, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 94, 'frame_number': 1539, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 97, 'frame_number': 1542, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 100, 'frame_number': 1545, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 103, 'frame_number': 1548, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 106, 'frame_number': 1551, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 109, 'frame_number': 1554, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 112, 'frame_number': 1557, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 115, 'frame_number': 1560, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 118, 'frame_number': 1563, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 121, 'frame_number': 1566, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 124, 'frame_number': 1569, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 127, 'frame_number': 1572, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 3, 'episode_frame_number': 130, 'frame_number': 1575, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 133, 'frame_number': 1578, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 136, 'frame_number': 1581, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 139, 'frame_number': 1584, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 142, 'frame_number': 1587, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 145, 'frame_number': 1590, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 148, 'frame_number': 1593, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 151, 'frame_number': 1596, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 154, 'frame_number': 1599, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 157, 'frame_number': 1602, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 160, 'frame_number': 1605, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 163, 'frame_number': 1608, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 166, 'frame_number': 1611, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 169, 'frame_number': 1614, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 172, 'frame_number': 1617, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 175, 'frame_number': 1620, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 178, 'frame_number': 1623, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 181, 'frame_number': 1626, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 184, 'frame_number': 1629, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 187, 'frame_number': 1632, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 190, 'frame_number': 1635, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 193, 'frame_number': 1638, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 196, 'frame_number': 1641, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 199, 'frame_number': 1644, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 202, 'frame_number': 1647, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 205, 'frame_number': 1650, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 208, 'frame_number': 1653, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 211, 'frame_number': 1656, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 214, 'frame_number': 1659, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 217, 'frame_number': 1662, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 220, 'frame_number': 1665, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 223, 'frame_number': 1668, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 226, 'frame_number': 1671, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 229, 'frame_number': 1674, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 232, 'frame_number': 1677, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 235, 'frame_number': 1680, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 238, 'frame_number': 1683, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 241, 'frame_number': 1686, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 244, 'frame_number': 1689, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 247, 'frame_number': 1692, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 250, 'frame_number': 1695, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 253, 'frame_number': 1698, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 256, 'frame_number': 1701, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 259, 'frame_number': 1704, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 262, 'frame_number': 1707, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 265, 'frame_number': 1710, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 268, 'frame_number': 1713, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 271, 'frame_number': 1716, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 274, 'frame_number': 1719, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 277, 'frame_number': 1722, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 280, 'frame_number': 1725, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 3, 'episode_frame_number': 283, 'frame_number': 1728, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 286, 'frame_number': 1731, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 289, 'frame_number': 1734, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 292, 'frame_number': 1737, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 295, 'frame_number': 1740, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 298, 'frame_number': 1743, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 301, 'frame_number': 1746, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 304, 'frame_number': 1749, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 307, 'frame_number': 1752, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 310, 'frame_number': 1755, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 313, 'frame_number': 1758, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 316, 'frame_number': 1761, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 319, 'frame_number': 1764, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 322, 'frame_number': 1767, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 325, 'frame_number': 1770, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 328, 'frame_number': 1773, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 331, 'frame_number': 1776, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 334, 'frame_number': 1779, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 337, 'frame_number': 1782, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 340, 'frame_number': 1785, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 343, 'frame_number': 1788, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 346, 'frame_number': 1791, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 349, 'frame_number': 1794, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 352, 'frame_number': 1797, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 355, 'frame_number': 1800, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 358, 'frame_number': 1803, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 361, 'frame_number': 1806, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 364, 'frame_number': 1809, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 367, 'frame_number': 1812, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 370, 'frame_number': 1815, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 373, 'frame_number': 1818, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 376, 'frame_number': 1821, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 379, 'frame_number': 1824, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 382, 'frame_number': 1827, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 385, 'frame_number': 1830, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 388, 'frame_number': 1833, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 391, 'frame_number': 1836, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 394, 'frame_number': 1839, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 397, 'frame_number': 1842, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 400, 'frame_number': 1845, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 403, 'frame_number': 1848, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 406, 'frame_number': 1851, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 409, 'frame_number': 1854, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 412, 'frame_number': 1857, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 415, 'frame_number': 1860, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 418, 'frame_number': 1863, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 421, 'frame_number': 1866, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 424, 'frame_number': 1869, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 427, 'frame_number': 1872, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 430, 'frame_number': 1875, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 433, 'frame_number': 1878, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 436, 'frame_number': 1881, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 3, 'episode_frame_number': 439, 'frame_number': 1884, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 442, 'frame_number': 1887, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 445, 'frame_number': 1890, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 448, 'frame_number': 1893, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 451, 'frame_number': 1896, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 454, 'frame_number': 1899, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 457, 'frame_number': 1902, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 460, 'frame_number': 1905, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 463, 'frame_number': 1908, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 466, 'frame_number': 1911, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 469, 'frame_number': 1914, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 3, 'episode_frame_number': 472, 'frame_number': 1917, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 475, 'frame_number': 1920, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 478, 'frame_number': 1923, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 481, 'frame_number': 1926, 'TimeLimit.truncated': False}]\n",
      "Reward: [-5.], info: [{'lives': 3, 'episode_frame_number': 484, 'frame_number': 1929, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 487, 'frame_number': 1932, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 490, 'frame_number': 1935, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 493, 'frame_number': 1938, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 496, 'frame_number': 1941, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 499, 'frame_number': 1944, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 502, 'frame_number': 1947, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 505, 'frame_number': 1950, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 508, 'frame_number': 1953, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 511, 'frame_number': 1956, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 514, 'frame_number': 1959, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 517, 'frame_number': 1962, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 520, 'frame_number': 1965, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 523, 'frame_number': 1968, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 526, 'frame_number': 1971, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 529, 'frame_number': 1974, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 532, 'frame_number': 1977, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 535, 'frame_number': 1980, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 538, 'frame_number': 1983, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 541, 'frame_number': 1986, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 544, 'frame_number': 1989, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 547, 'frame_number': 1992, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 550, 'frame_number': 1995, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 553, 'frame_number': 1998, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 556, 'frame_number': 2001, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 3, 'episode_frame_number': 559, 'frame_number': 2004, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 562, 'frame_number': 2007, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 565, 'frame_number': 2010, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 568, 'frame_number': 2013, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 571, 'frame_number': 2016, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 574, 'frame_number': 2019, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 577, 'frame_number': 2022, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 580, 'frame_number': 2025, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 583, 'frame_number': 2028, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 586, 'frame_number': 2031, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 589, 'frame_number': 2034, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 592, 'frame_number': 2037, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 595, 'frame_number': 2040, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 598, 'frame_number': 2043, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 601, 'frame_number': 2046, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 604, 'frame_number': 2049, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 607, 'frame_number': 2052, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 610, 'frame_number': 2055, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 613, 'frame_number': 2058, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 616, 'frame_number': 2061, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 619, 'frame_number': 2064, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 622, 'frame_number': 2067, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 625, 'frame_number': 2070, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 628, 'frame_number': 2073, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 631, 'frame_number': 2076, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 634, 'frame_number': 2079, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 637, 'frame_number': 2082, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 640, 'frame_number': 2085, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 643, 'frame_number': 2088, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 646, 'frame_number': 2091, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 649, 'frame_number': 2094, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 652, 'frame_number': 2097, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 655, 'frame_number': 2100, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 658, 'frame_number': 2103, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 661, 'frame_number': 2106, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 664, 'frame_number': 2109, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 667, 'frame_number': 2112, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 670, 'frame_number': 2115, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 673, 'frame_number': 2118, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 676, 'frame_number': 2121, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 679, 'frame_number': 2124, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 682, 'frame_number': 2127, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 685, 'frame_number': 2130, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 688, 'frame_number': 2133, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 691, 'frame_number': 2136, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 694, 'frame_number': 2139, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 697, 'frame_number': 2142, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 700, 'frame_number': 2145, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 703, 'frame_number': 2148, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 706, 'frame_number': 2151, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 709, 'frame_number': 2154, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 712, 'frame_number': 2157, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 715, 'frame_number': 2160, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 718, 'frame_number': 2163, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 721, 'frame_number': 2166, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 724, 'frame_number': 2169, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 727, 'frame_number': 2172, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 730, 'frame_number': 2175, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 733, 'frame_number': 2178, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 736, 'frame_number': 2181, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 739, 'frame_number': 2184, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 742, 'frame_number': 2187, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 745, 'frame_number': 2190, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 748, 'frame_number': 2193, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 751, 'frame_number': 2196, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 754, 'frame_number': 2199, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 757, 'frame_number': 2202, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 760, 'frame_number': 2205, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 763, 'frame_number': 2208, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 766, 'frame_number': 2211, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 769, 'frame_number': 2214, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 772, 'frame_number': 2217, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 775, 'frame_number': 2220, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 778, 'frame_number': 2223, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 781, 'frame_number': 2226, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 784, 'frame_number': 2229, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 787, 'frame_number': 2232, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 790, 'frame_number': 2235, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 793, 'frame_number': 2238, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 796, 'frame_number': 2241, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 799, 'frame_number': 2244, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 802, 'frame_number': 2247, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 805, 'frame_number': 2250, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 808, 'frame_number': 2253, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 811, 'frame_number': 2256, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 814, 'frame_number': 2259, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 817, 'frame_number': 2262, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 820, 'frame_number': 2265, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 823, 'frame_number': 2268, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 826, 'frame_number': 2271, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 829, 'frame_number': 2274, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 832, 'frame_number': 2277, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 835, 'frame_number': 2280, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 838, 'frame_number': 2283, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 841, 'frame_number': 2286, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 844, 'frame_number': 2289, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 847, 'frame_number': 2292, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 850, 'frame_number': 2295, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 853, 'frame_number': 2298, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 856, 'frame_number': 2301, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 859, 'frame_number': 2304, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 862, 'frame_number': 2307, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 865, 'frame_number': 2310, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 868, 'frame_number': 2313, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 871, 'frame_number': 2316, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 874, 'frame_number': 2319, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 877, 'frame_number': 2322, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 880, 'frame_number': 2325, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 883, 'frame_number': 2328, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 886, 'frame_number': 2331, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 889, 'frame_number': 2334, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 892, 'frame_number': 2337, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 895, 'frame_number': 2340, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 898, 'frame_number': 2343, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 901, 'frame_number': 2346, 'TimeLimit.truncated': False}]\n",
      "Reward: [-10.], info: [{'lives': 2, 'episode_frame_number': 904, 'frame_number': 2349, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 907, 'frame_number': 2352, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 910, 'frame_number': 2355, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 913, 'frame_number': 2358, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 916, 'frame_number': 2361, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 919, 'frame_number': 2364, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 922, 'frame_number': 2367, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 925, 'frame_number': 2370, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 928, 'frame_number': 2373, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 931, 'frame_number': 2376, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 934, 'frame_number': 2379, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 937, 'frame_number': 2382, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 940, 'frame_number': 2385, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 943, 'frame_number': 2388, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 946, 'frame_number': 2391, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 949, 'frame_number': 2394, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 952, 'frame_number': 2397, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 955, 'frame_number': 2400, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 958, 'frame_number': 2403, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 961, 'frame_number': 2406, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 964, 'frame_number': 2409, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 967, 'frame_number': 2412, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 970, 'frame_number': 2415, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 973, 'frame_number': 2418, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 976, 'frame_number': 2421, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 979, 'frame_number': 2424, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 982, 'frame_number': 2427, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 2, 'episode_frame_number': 985, 'frame_number': 2430, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 988, 'frame_number': 2433, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 991, 'frame_number': 2436, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 994, 'frame_number': 2439, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 997, 'frame_number': 2442, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1000, 'frame_number': 2445, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1003, 'frame_number': 2448, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1006, 'frame_number': 2451, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1009, 'frame_number': 2454, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1012, 'frame_number': 2457, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1015, 'frame_number': 2460, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1018, 'frame_number': 2463, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1021, 'frame_number': 2466, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1024, 'frame_number': 2469, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1027, 'frame_number': 2472, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1030, 'frame_number': 2475, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1033, 'frame_number': 2478, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1036, 'frame_number': 2481, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1039, 'frame_number': 2484, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1042, 'frame_number': 2487, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1045, 'frame_number': 2490, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1048, 'frame_number': 2493, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1051, 'frame_number': 2496, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 2, 'episode_frame_number': 1054, 'frame_number': 2499, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1057, 'frame_number': 2502, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1060, 'frame_number': 2505, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1063, 'frame_number': 2508, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1066, 'frame_number': 2511, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1069, 'frame_number': 2514, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1072, 'frame_number': 2517, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1075, 'frame_number': 2520, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1078, 'frame_number': 2523, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1081, 'frame_number': 2526, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1084, 'frame_number': 2529, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1087, 'frame_number': 2532, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1090, 'frame_number': 2535, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1093, 'frame_number': 2538, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1096, 'frame_number': 2541, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1099, 'frame_number': 2544, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1102, 'frame_number': 2547, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1105, 'frame_number': 2550, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1108, 'frame_number': 2553, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1111, 'frame_number': 2556, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1114, 'frame_number': 2559, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1117, 'frame_number': 2562, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1120, 'frame_number': 2565, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1123, 'frame_number': 2568, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1126, 'frame_number': 2571, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1129, 'frame_number': 2574, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1132, 'frame_number': 2577, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1135, 'frame_number': 2580, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1138, 'frame_number': 2583, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1141, 'frame_number': 2586, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1144, 'frame_number': 2589, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1147, 'frame_number': 2592, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1150, 'frame_number': 2595, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1153, 'frame_number': 2598, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1156, 'frame_number': 2601, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1159, 'frame_number': 2604, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1162, 'frame_number': 2607, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1165, 'frame_number': 2610, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1168, 'frame_number': 2613, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1171, 'frame_number': 2616, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1174, 'frame_number': 2619, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1177, 'frame_number': 2622, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1180, 'frame_number': 2625, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1183, 'frame_number': 2628, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1186, 'frame_number': 2631, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1189, 'frame_number': 2634, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1192, 'frame_number': 2637, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1195, 'frame_number': 2640, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1198, 'frame_number': 2643, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1201, 'frame_number': 2646, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1204, 'frame_number': 2649, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1207, 'frame_number': 2652, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1210, 'frame_number': 2655, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1213, 'frame_number': 2658, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1216, 'frame_number': 2661, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1219, 'frame_number': 2664, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1222, 'frame_number': 2667, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1225, 'frame_number': 2670, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1228, 'frame_number': 2673, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1231, 'frame_number': 2676, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1234, 'frame_number': 2679, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1237, 'frame_number': 2682, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1240, 'frame_number': 2685, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1243, 'frame_number': 2688, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1246, 'frame_number': 2691, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1249, 'frame_number': 2694, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1252, 'frame_number': 2697, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1255, 'frame_number': 2700, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1258, 'frame_number': 2703, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1261, 'frame_number': 2706, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1264, 'frame_number': 2709, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1267, 'frame_number': 2712, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1270, 'frame_number': 2715, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1273, 'frame_number': 2718, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1276, 'frame_number': 2721, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1279, 'frame_number': 2724, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1282, 'frame_number': 2727, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1285, 'frame_number': 2730, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1288, 'frame_number': 2733, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1291, 'frame_number': 2736, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1294, 'frame_number': 2739, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 2, 'episode_frame_number': 1297, 'frame_number': 2742, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1300, 'frame_number': 2745, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1303, 'frame_number': 2748, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1306, 'frame_number': 2751, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1309, 'frame_number': 2754, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1312, 'frame_number': 2757, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1315, 'frame_number': 2760, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1318, 'frame_number': 2763, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1321, 'frame_number': 2766, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1324, 'frame_number': 2769, 'TimeLimit.truncated': False}]\n",
      "Reward: [1.], info: [{'lives': 2, 'episode_frame_number': 1327, 'frame_number': 2772, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1330, 'frame_number': 2775, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1333, 'frame_number': 2778, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1336, 'frame_number': 2781, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1339, 'frame_number': 2784, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1342, 'frame_number': 2787, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1345, 'frame_number': 2790, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1348, 'frame_number': 2793, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1351, 'frame_number': 2796, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1354, 'frame_number': 2799, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1357, 'frame_number': 2802, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1360, 'frame_number': 2805, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1363, 'frame_number': 2808, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1366, 'frame_number': 2811, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1369, 'frame_number': 2814, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1372, 'frame_number': 2817, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1375, 'frame_number': 2820, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1378, 'frame_number': 2823, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1381, 'frame_number': 2826, 'TimeLimit.truncated': False}]\n",
      "Reward: [-5.], info: [{'lives': 2, 'episode_frame_number': 1384, 'frame_number': 2829, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1387, 'frame_number': 2832, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1390, 'frame_number': 2835, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1393, 'frame_number': 2838, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1396, 'frame_number': 2841, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1399, 'frame_number': 2844, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1402, 'frame_number': 2847, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1405, 'frame_number': 2850, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1408, 'frame_number': 2853, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1411, 'frame_number': 2856, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1414, 'frame_number': 2859, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1417, 'frame_number': 2862, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1420, 'frame_number': 2865, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1423, 'frame_number': 2868, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1426, 'frame_number': 2871, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1429, 'frame_number': 2874, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1432, 'frame_number': 2877, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1435, 'frame_number': 2880, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1438, 'frame_number': 2883, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1441, 'frame_number': 2886, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1444, 'frame_number': 2889, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1447, 'frame_number': 2892, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1450, 'frame_number': 2895, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1453, 'frame_number': 2898, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1456, 'frame_number': 2901, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1459, 'frame_number': 2904, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1462, 'frame_number': 2907, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1465, 'frame_number': 2910, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1468, 'frame_number': 2913, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1471, 'frame_number': 2916, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1474, 'frame_number': 2919, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1477, 'frame_number': 2922, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1480, 'frame_number': 2925, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1483, 'frame_number': 2928, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1486, 'frame_number': 2931, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1489, 'frame_number': 2934, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1492, 'frame_number': 2937, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1495, 'frame_number': 2940, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1498, 'frame_number': 2943, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1501, 'frame_number': 2946, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1504, 'frame_number': 2949, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1507, 'frame_number': 2952, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1510, 'frame_number': 2955, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1513, 'frame_number': 2958, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1516, 'frame_number': 2961, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1519, 'frame_number': 2964, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1522, 'frame_number': 2967, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1525, 'frame_number': 2970, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1528, 'frame_number': 2973, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1531, 'frame_number': 2976, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1534, 'frame_number': 2979, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1537, 'frame_number': 2982, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1540, 'frame_number': 2985, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1543, 'frame_number': 2988, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1546, 'frame_number': 2991, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1549, 'frame_number': 2994, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1552, 'frame_number': 2997, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1555, 'frame_number': 3000, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1558, 'frame_number': 3003, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1561, 'frame_number': 3006, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1564, 'frame_number': 3009, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1567, 'frame_number': 3012, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1570, 'frame_number': 3015, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 2, 'episode_frame_number': 1573, 'frame_number': 3018, 'TimeLimit.truncated': False}]\n",
      "Reward: [-10.], info: [{'lives': 1, 'episode_frame_number': 1576, 'frame_number': 3021, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1579, 'frame_number': 3024, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1582, 'frame_number': 3027, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1585, 'frame_number': 3030, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1588, 'frame_number': 3033, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1591, 'frame_number': 3036, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1594, 'frame_number': 3039, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1597, 'frame_number': 3042, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1600, 'frame_number': 3045, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1603, 'frame_number': 3048, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1606, 'frame_number': 3051, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1609, 'frame_number': 3054, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1612, 'frame_number': 3057, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1615, 'frame_number': 3060, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1618, 'frame_number': 3063, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1621, 'frame_number': 3066, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1624, 'frame_number': 3069, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1627, 'frame_number': 3072, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1630, 'frame_number': 3075, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1633, 'frame_number': 3078, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1636, 'frame_number': 3081, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1639, 'frame_number': 3084, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1642, 'frame_number': 3087, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1645, 'frame_number': 3090, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1648, 'frame_number': 3093, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1651, 'frame_number': 3096, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1654, 'frame_number': 3099, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1657, 'frame_number': 3102, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1660, 'frame_number': 3105, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1663, 'frame_number': 3108, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1666, 'frame_number': 3111, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1669, 'frame_number': 3114, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1672, 'frame_number': 3117, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1675, 'frame_number': 3120, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1678, 'frame_number': 3123, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1681, 'frame_number': 3126, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1684, 'frame_number': 3129, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1687, 'frame_number': 3132, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1690, 'frame_number': 3135, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1693, 'frame_number': 3138, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1696, 'frame_number': 3141, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1699, 'frame_number': 3144, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1702, 'frame_number': 3147, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1705, 'frame_number': 3150, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1708, 'frame_number': 3153, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1711, 'frame_number': 3156, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1714, 'frame_number': 3159, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1717, 'frame_number': 3162, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1720, 'frame_number': 3165, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1723, 'frame_number': 3168, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1726, 'frame_number': 3171, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1729, 'frame_number': 3174, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1732, 'frame_number': 3177, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1735, 'frame_number': 3180, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1738, 'frame_number': 3183, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1741, 'frame_number': 3186, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1744, 'frame_number': 3189, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1747, 'frame_number': 3192, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1750, 'frame_number': 3195, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1753, 'frame_number': 3198, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1756, 'frame_number': 3201, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1759, 'frame_number': 3204, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1762, 'frame_number': 3207, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1765, 'frame_number': 3210, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1768, 'frame_number': 3213, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1771, 'frame_number': 3216, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1774, 'frame_number': 3219, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1777, 'frame_number': 3222, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1780, 'frame_number': 3225, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1783, 'frame_number': 3228, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1786, 'frame_number': 3231, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1789, 'frame_number': 3234, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1792, 'frame_number': 3237, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1795, 'frame_number': 3240, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1798, 'frame_number': 3243, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1801, 'frame_number': 3246, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1804, 'frame_number': 3249, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1807, 'frame_number': 3252, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1810, 'frame_number': 3255, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1813, 'frame_number': 3258, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1816, 'frame_number': 3261, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1819, 'frame_number': 3264, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1822, 'frame_number': 3267, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1825, 'frame_number': 3270, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1828, 'frame_number': 3273, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1831, 'frame_number': 3276, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1834, 'frame_number': 3279, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1837, 'frame_number': 3282, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1840, 'frame_number': 3285, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1843, 'frame_number': 3288, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1846, 'frame_number': 3291, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1849, 'frame_number': 3294, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1852, 'frame_number': 3297, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1855, 'frame_number': 3300, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1858, 'frame_number': 3303, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1861, 'frame_number': 3306, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1864, 'frame_number': 3309, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1867, 'frame_number': 3312, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1870, 'frame_number': 3315, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1873, 'frame_number': 3318, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1876, 'frame_number': 3321, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1879, 'frame_number': 3324, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1882, 'frame_number': 3327, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1885, 'frame_number': 3330, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 1, 'episode_frame_number': 1888, 'frame_number': 3333, 'TimeLimit.truncated': False}]\n",
      "Reward: [-10.], info: [{'lives': 0, 'episode_frame_number': 1889, 'frame_number': 3334, 'episode': {'r': -41.0, 'l': 630, 't': 60.259972}, 'TimeLimit.truncated': False, 'terminal_observation': array([[[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        ...,\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0],\n",
      "        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 19, 'frame_number': 3364, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 22, 'frame_number': 3367, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 25, 'frame_number': 3370, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 28, 'frame_number': 3373, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 31, 'frame_number': 3376, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 34, 'frame_number': 3379, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 37, 'frame_number': 3382, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 40, 'frame_number': 3385, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 43, 'frame_number': 3388, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 46, 'frame_number': 3391, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 49, 'frame_number': 3394, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 52, 'frame_number': 3397, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 55, 'frame_number': 3400, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 58, 'frame_number': 3403, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 4, 'episode_frame_number': 61, 'frame_number': 3406, 'TimeLimit.truncated': False}]\n",
      "Reward: [-10.], info: [{'lives': 3, 'episode_frame_number': 64, 'frame_number': 3409, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 67, 'frame_number': 3412, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 70, 'frame_number': 3415, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 73, 'frame_number': 3418, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 76, 'frame_number': 3421, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 79, 'frame_number': 3424, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 82, 'frame_number': 3427, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 85, 'frame_number': 3430, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 88, 'frame_number': 3433, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 91, 'frame_number': 3436, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 94, 'frame_number': 3439, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 97, 'frame_number': 3442, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 100, 'frame_number': 3445, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 103, 'frame_number': 3448, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 106, 'frame_number': 3451, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 109, 'frame_number': 3454, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 112, 'frame_number': 3457, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 115, 'frame_number': 3460, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 118, 'frame_number': 3463, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 121, 'frame_number': 3466, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 124, 'frame_number': 3469, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 127, 'frame_number': 3472, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 130, 'frame_number': 3475, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 133, 'frame_number': 3478, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 136, 'frame_number': 3481, 'TimeLimit.truncated': False}]\n",
      "Reward: [0.], info: [{'lives': 3, 'episode_frame_number': 139, 'frame_number': 3484, 'TimeLimit.truncated': False}]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m):\n\u001b[0;32m     14\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs, deterministic\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Use deterministic=True for evaluation\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43mvec_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Perform a step\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReward: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreward\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, info: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minfo\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     17\u001b[0m     vec_env\u001b[38;5;241m.\u001b[39mrender()  \u001b[38;5;66;03m# Optional: Visualize the gameplay\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\devpa\\anaconda3\\envs\\atari\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devpa\\anaconda3\\envs\\atari\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\Users\\devpa\\anaconda3\\envs\\atari\\lib\\site-packages\\stable_baselines3\\common\\monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "File \u001b[1;32mc:\\Users\\devpa\\anaconda3\\envs\\atari\\lib\\site-packages\\gymnasium\\wrappers\\stateful_observation.py:416\u001b[0m, in \u001b[0;36mFrameStackObservation.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[0;32m    407\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    408\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment, appending the observation to the frame buffer.\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \n\u001b[0;32m    410\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[38;5;124;03m        Stacked observations, reward, terminated, truncated, and info from the environment\u001b[39;00m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 416\u001b[0m     obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_queue\u001b[38;5;241m.\u001b[39mappend(obs)\n\u001b[0;32m    419\u001b[0m     updated_obs \u001b[38;5;241m=\u001b[39m deepcopy(\n\u001b[0;32m    420\u001b[0m         concatenate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mobservation_space, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_queue, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstacked_obs)\n\u001b[0;32m    421\u001b[0m     )\n",
      "Cell \u001b[1;32mIn[150], line 21\u001b[0m, in \u001b[0;36mLifePenaltyWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_action \u001b[38;5;241m=\u001b[39m action\n\u001b[1;32m---> 21\u001b[0m     obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m reward \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m40\u001b[39m, \u001b[38;5;241m50\u001b[39m]:\n\u001b[0;32m     24\u001b[0m         reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpoint_reward\n",
      "File \u001b[1;32mc:\\Users\\devpa\\anaconda3\\envs\\atari\\lib\\site-packages\\gymnasium\\wrappers\\atari_preprocessing.py:162\u001b[0m, in \u001b[0;36mAtariPreprocessing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    159\u001b[0m total_reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m, {}\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe_skip):\n\u001b[1;32m--> 162\u001b[0m     _, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgame_over \u001b[38;5;241m=\u001b[39m terminated\n",
      "File \u001b[1;32mc:\\Users\\devpa\\anaconda3\\envs\\atari\\lib\\site-packages\\gymnasium\\wrappers\\common.py:393\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 393\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devpa\\anaconda3\\envs\\atari\\lib\\site-packages\\gymnasium\\core.py:322\u001b[0m, in \u001b[0;36mWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m, action: WrapperActType\n\u001b[0;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[WrapperObsType, SupportsFloat, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]]:\n\u001b[0;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Uses the :meth:`step` of the :attr:`env` that can be overwritten to change the returned data.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devpa\\anaconda3\\envs\\atari\\lib\\site-packages\\gymnasium\\wrappers\\common.py:285\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devpa\\anaconda3\\envs\\atari\\lib\\site-packages\\ale_py\\env.py:299\u001b[0m, in \u001b[0;36mAtariEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    297\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(frameskip):\n\u001b[1;32m--> 299\u001b[0m     reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mact(action_idx, strength)\n\u001b[0;32m    301\u001b[0m is_terminal \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgame_over(with_truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    302\u001b[0m is_truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39male\u001b[38;5;241m.\u001b[39mgame_truncated()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = DQN.load(\"new_v16_dqn_galaxian_long.zip\")\n",
    "\n",
    "# Create the environment with render_mode\n",
    "\n",
    "vec_env = make_vec_env(\n",
    "    lambda: make_env(seed=np.random.randint(0, 50), mode='human')(), \n",
    "    n_envs=1\n",
    ")\n",
    "\n",
    "# Test the model\n",
    "obs = vec_env.reset()\n",
    "for _ in range(10000):\n",
    "    action, _states = model.predict(obs, deterministic=True)  # Use deterministic=True for evaluation\n",
    "    obs, reward, done, info = vec_env.step(action)  # Perform a step\n",
    "    print(f\"Reward: {reward}, info: {info}\")\n",
    "    vec_env.render()  # Optional: Visualize the gameplay\n",
    "    if done:\n",
    "        obs = vec_env.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atari",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
